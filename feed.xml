<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Antoine Broyelle</title>
    <description>Antoine Broyelle - Personnal Blog</description>
    <link>https://antoinebrl.github.io//</link>
    <atom:link href="https://antoinebrl.github.io//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 09 May 2022 14:54:18 +0000</pubDate>
    <lastBuildDate>Mon, 09 May 2022 14:54:18 +0000</lastBuildDate>
    <generator>Jekyll v3.9.0</generator>
    
      
      <item>
        <title>Learning to Land on Mars with Reinforcement Learning</title>
        <description>&lt;h2 id=&quot;codingame-mars-lander&quot;&gt;CodinGame Mars Lander&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.codingame.com/multiplayer/optimization/mars-lander&quot;&gt;This game’s&lt;/a&gt;
goal is to land the spacecraft while using as few propellants as possible.
The mission is successful only if the rover reaches a flat ground,
at a low speed, without any tilt.&lt;/p&gt;

&lt;p&gt;For each environment, we’re given Mars’s surface as pairs of coordinates, as well as the
lander’s current state. That state includes position, speed,
angle, current engine thrust, and remaining fuel volume. At each iteration,
the program has less than 100ms to output the desired rotation and thrust power.&lt;/p&gt;

&lt;p&gt;One test case looks like this:&lt;/p&gt;

&lt;figure&gt;
    &lt;video width=&quot;80%&quot; controls=&quot;&quot; style=&quot;margin:0 auto 2em auto;display:block&quot;&gt;
      &lt;source src=&quot;/assets/videos/marslander.mov&quot; type=&quot;video/mp4&quot; /&gt;
    Your browser does not support the video tag.
    &lt;/video&gt;
    &lt;figcaption&gt;Vid 1 — CodinGame Mars Lander&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;coding-the-game&quot;&gt;Coding the Game&lt;/h2&gt;

&lt;p&gt;The CodinGame platform is not designed to gather feedback on millions of
simulations and improve on them. The only way to circumvent this limitation
is by reimplementing the game.&lt;/p&gt;

&lt;h3 id=&quot;the-interface&quot;&gt;The Interface&lt;/h3&gt;

&lt;p&gt;Because I wanted to do some reinforcement learning, I decided to follow the
&lt;a href=&quot;https://gym.openai.com/&quot;&gt;Gym package&lt;/a&gt;’s &lt;a href=&quot;https://github.com/openai/gym/blob/c6b6754b128c095df49c74785277d8d5e9f81755/gym/core.py#L17&quot;&gt;Environment&lt;/a&gt; class interface. Gym is a collection of
test environments used to benchmark reinforcement learning algorithms.
By complying with this interface, I could use many algorithms out of the box (or so I thought).&lt;/p&gt;

&lt;p&gt;All Gym Environments follow the same interface, with two fields and three methods:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;action_space&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;observation_space&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reset()&lt;/code&gt;: called to generate a new game&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;step(action)&lt;/code&gt;: returns the new observations of the environment given a specific action&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;render()&lt;/code&gt;: visualizes the agent in its environment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At first, I thought I could go without implementing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;render&lt;/code&gt;, but I was wrong.
As with any other machine learning task, visualization is of the utmost
importance for debugging.&lt;/p&gt;

&lt;h3 id=&quot;action-space&quot;&gt;Action Space&lt;/h3&gt;

&lt;p&gt;The algorithm controls the spacecraft’s thrust and orientation.
The thrust has 5 levels between 0 and 4, and the angle is expressed in
degrees between -90 and 90.&lt;/p&gt;

&lt;p&gt;Rather than working in absolutes values, I decided that the action space
would be a relative change in thrust and angle. The engine supports only
a +/-1 change in thrust, and the orientation cannot change more than
15 degrees in absolute value.&lt;/p&gt;

&lt;p&gt;Thrust and angle can be represented with categorical variables, with 3
and 31 mutually exclusive values respectively. Another possible characterization,
which I decided to use, is to represent the action space as two continuous variables.
For stability during the training, I normalized these values between -1 and 1.&lt;/p&gt;

&lt;h3 id=&quot;observation-space-and-policy-network&quot;&gt;Observation Space and Policy Network&lt;/h3&gt;

&lt;p&gt;Defining the observation space is a bit more challenging than it is for
the action space. First, the agent expects a fixed-length input, but the
ground is provided as a broken line with up to 30 points. To fulfill this
requirement, I iteratively broke the longest segment into two by
adding an intermediate point, until I reached thrity 2D points, for a total
of 60 elements.&lt;/p&gt;

&lt;p&gt;I then concatenated to these 60 elements the seven values that fully characterize the
rover’s dynamic: x and y position, horizontal and vertical speed, angle,
current thrust, and remaining propellant. I normalized these values
between 0 and 1, or -1 and 1 if negative values are allowed.&lt;/p&gt;

&lt;p&gt;In the early experiments, the fully connected policy was clearly
struggling to identify the landing pad. The rover exhibited completely
different behavior when the ground was translated horizontally because
a slight offset creates a completely different representation of the ground
once the surface is broken down into 30 points.&lt;/p&gt;

&lt;p&gt;Changing the policy to a convolutional neural network (CNN) could have helped
identify the landing area. By design, CNNs (unlike MLP) are translation
equivariant. In addition, CNNs could have also eliminated the problem of
fixed-length input I addressed above. Indeed, their number of
parameters is independent of the input size.&lt;/p&gt;

&lt;p&gt;After a few trials, it became clear that this approach would require a lot
more effort to achive success. When using a CNN to extract an abstract
ground representation, at some point these features need to be merged
with the rover state.
When should they merge? What should be the CNN’s capacity compared
to that of the MLP? How should both networks be initialized? Would they work with
the same learning rate? I ran a few experiments, but none of them were
firmly conclusive.&lt;/p&gt;

&lt;p&gt;In the end, to avoid going mad, I decided to use an MLP-based policy
but to help the agent by providing a bit more information.
The trick was to add the x and y coordinates of the two extremities
of the flat section. This extra information can easily be computed by hand,
so why not feed it to the model?&lt;/p&gt;

&lt;h3 id=&quot;simulation&quot;&gt;Simulation&lt;/h3&gt;

&lt;p&gt;When implementing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reset()&lt;/code&gt; function, I wanted to utilize as many
environments as possible. I initially thought that generating a random ground surface
and random rover state would do the job.&lt;/p&gt;

&lt;p&gt;However, it turned out that not all these environments could be solved. For example,
the rover might exit the frame before compensating for the initial speed,
or the solution might consume an extremely high propellant volume.
Finding a valid initial state might be as hard as solving the problem itself.&lt;/p&gt;

&lt;p&gt;Clearly these unsolvable cases were penalising the training.
This comes as no surprise; the same rule applies for any other machine learning
task or algorithm. In the end, I decided to start from the five test cases
CodinGame provided and to apply some random augmentations.&lt;/p&gt;

&lt;h2 id=&quot;reinforcement-learning&quot;&gt;Reinforcement Learning&lt;/h2&gt;

&lt;h3 id=&quot;policy-gradient&quot;&gt;Policy Gradient&lt;/h3&gt;

&lt;p&gt;In reinforcement learning, an agent interacts with the environment via its
actions at each time step. In return, the agent is granted a reward and is
placed in a new state. The main assumption is that the future
state depends only on the current state and the action taken. The objective
is to maximise the rewards accumulated over the entire sequence.&lt;/p&gt;

&lt;p&gt;Two classes of optimization algorithms are popular: Q-learning and policy gradient methods.
The former aims to approximate the best transition function from one step
to another. The latter directly optimizes for the best action. Despite being
less popular, policy gradient methods have the advantage of supporting continuous
action space and tend to converge faster.&lt;/p&gt;

&lt;p&gt;For this task, I used a policy gradient method known as
&lt;a href=&quot;https://arxiv.org/abs/1707.06347&quot;&gt;Proximal Policy Optimization (a.k.a PPO)&lt;/a&gt;.
In its &lt;a href=&quot;https://arxiv.org/abs/2009.10897&quot;&gt;revisited version&lt;/a&gt;,
PPO introduces a simple twist to the vanilla policy gradient method by
clipping the update magnitude. By reducing the variance and
taking smaller optimization steps, the learning becomes more stable, with
fewer parameter tweaks.&lt;/p&gt;

&lt;p&gt;If you want to learn more about PPO and its siblings, I recommend the article
&lt;a href=&quot;https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html&quot;&gt;Policy Gradient Algorithms&lt;/a&gt;
by Lilian Weng, Applied AI Research Lead at OpenAI.&lt;/p&gt;

&lt;h3 id=&quot;action-noise&quot;&gt;Action Noise&lt;/h3&gt;

&lt;p&gt;In the first experiments, the rover was very shaky, as its tilt oscillated
around the optimal value. To eliminate this jerky motion, I used
gSDE, which stands for &lt;a href=&quot;https://arxiv.org/abs/2005.05719&quot;&gt;generalized State-Dependent Exploration&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In reinforcement learning, it’s important to balance exploitation with exploration.
Without exploring the action space, the agent has no way to find
potential improvements. The exploration is often achieved by adding independent
Gaussian noise to the action distribution.&lt;/p&gt;

&lt;p&gt;The gSDE authors propose a state-dependent noise. That way, during one episode,
the action remains the same for a given state rather than oscillating around a mean value. 
This exploration technique leads to smoother trajectories.&lt;/p&gt;

&lt;figure&gt;
    &lt;video width=&quot;80%&quot; controls=&quot;&quot; style=&quot;margin:0 auto 2em auto;display:block&quot;&gt;
      &lt;source src=&quot;/assets/videos/marslander_no-sde.mov&quot; type=&quot;video/mp4&quot; /&gt;
    Your browser does not support the video tag.
    &lt;/video&gt;
    &lt;figcaption&gt;Vid. 2 — Jerky trajectory without gSDE&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;reward-shaping&quot;&gt;Reward Shaping&lt;/h3&gt;

&lt;p&gt;The reward is an incentive mechanism that tells the agent how well it’s performing.
Crafting this function correctly is a big deal, given that the goal is
to maximise the cumulative rewards.&lt;/p&gt;

&lt;h4 id=&quot;reward-sparsity&quot;&gt;Reward Sparsity&lt;/h4&gt;

&lt;p&gt;The first difficulty is reward sparsity. Let’s say we want to train a model
to solve a Rubik’s cube. What would be a good reward function, knowing
that there is only one good solution among 43,252,003,274,489,856,000 (~43 quintillion)
possible states?
It would take years to solve if we relied only on luck.
If you’re interested in this problem, have a look at
&lt;a href=&quot;https://arxiv.org/abs/1805.07470&quot;&gt;Solving the Rubik’s Cube Without Human Knowledge&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In our case, the rover has correctly landed if it grounds on a flat surface
with a tilt angle of exactly 0° and a vertical and horizontal speed lower
than 40 m/s and 20 m/s respectively. During training, I decided to loosen
the angle restriction to anything between -15° and 15°, which increased the
chances of reaching a valid terminal state.
At inference, some post-processing code compensates for the rotation
when the rover is about to land.&lt;/p&gt;

&lt;h4 id=&quot;reward-scale&quot;&gt;Reward Scale&lt;/h4&gt;

&lt;p&gt;If the rover runs out of fuel, or if it leaves the frame, it
receives a negative reward of -150, and the episode ends.
A valid terminal state yields a reward equal to the amount of remaining
propellant.&lt;/p&gt;

&lt;p&gt;By default, if the rover is still flying, it earns a reward of +1.
In general, positive rewards encourage longer episodes, as the agent continues
accumulating. On the other hand, negative rewards urge the agent
to reach a terminal state as soon as possible to avoid penalties.&lt;/p&gt;

&lt;p&gt;For this problem, shorter episodes should ideally consume less fuel.
However, using the quantity of remaining fuel as a terminal reward
creates a massive step function that encourages early misson completion.
By maintaining a small positive reward at each step, the
rover quickly learns to hover.&lt;/p&gt;

&lt;figure&gt;
    &lt;video width=&quot;80%&quot; controls=&quot;&quot; style=&quot;margin:0 auto 2em auto;display:block&quot;&gt;
      &lt;source src=&quot;/assets/videos/marslander_hover.mov&quot; type=&quot;video/mp4&quot; /&gt;
    Your browser does not support the video tag.
    &lt;/video&gt;
    &lt;figcaption&gt;Vid. 3 — Learning to hover&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;For the rest, not all mistakes are created equal. I decided to 
give a reward of -75 if speed and angle were correct when touching
non-flat ground, as well as a -50 reward if the spacecraft crashed
on the landing area.
Without more experiments, it’s unclear whether if the distinction of
collisions represents any advantage.&lt;/p&gt;

&lt;h4 id=&quot;not-taking-shortcuts&quot;&gt;Not Taking Shortcuts&lt;/h4&gt;

&lt;p&gt;Previously, I talked about helping the model identify the arrival site.
One idea was to change the policy structure by replacing the MLP with a CNN.
I used the solution of adding this information in the input vector. A third
possibility was to change the reward function to incorporate a notion of
distance to the landing area.&lt;/p&gt;

&lt;p&gt;I ran a few experiments in which the reward was the negative
Euclidean distance between the landing site and the crash site.
As it turned out, this strategy instructs the agent to move in a straight
line toward the target.&lt;/p&gt;

&lt;p&gt;If  the starting position and the landing site have no direct path between them,
the agent would have to undergo a long sequence of decreasing rewards
to reach the desired destination. Despite being an intuitive solution,
using the Euclidean distance as a negative reward is a strong inductive bias
that reduces the agent’s exploration capabilities.&lt;/p&gt;

&lt;figure&gt;
    &lt;video width=&quot;80%&quot; controls=&quot;&quot; style=&quot;margin:0 auto 2em auto;display:block&quot;&gt;
      &lt;source src=&quot;/assets/videos/marslander_l2dist.mov&quot; type=&quot;video/mp4&quot; /&gt;
    Your browser does not support the video tag.
    &lt;/video&gt;
    &lt;figcaption&gt;Vid. 4 — Suboptimal strategy when minimizing distance to landing site&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;hyper-parameters&quot;&gt;Hyper-Parameters&lt;/h3&gt;

&lt;p&gt;In computer vision or natural language processing, starting the training from a
pretrained model is good practice: it speeds up training
and tends to improve performance. However, this project has
no available pretrained model.&lt;/p&gt;

&lt;p&gt;Another element that is even more annoying is the absence of good hyperparameters.
At first, I used the default values, but the training suffered from
catastrophic forgetting. As you can see on the graph below, the mean reward
drops sharply and struggles to recover.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/rl-mars-lander-unstable-learning.png&quot; alt=&quot;Catastrophic forgetting&quot; style=&quot;width:100%;max-width:680px&quot; /&gt;
  &lt;figcaption&gt;Fig 1 — Mean Episode Reward — Catastrophic forgetting.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Rather than starting an extensive hyperparameter search, I took inspiration
from the &lt;a href=&quot;https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml&quot;&gt;RL baselines3 Zoo configurations&lt;/a&gt;.
After a few tweaks, I had a great set of values. Still, the policy
could doubtless be further improved with hyperparameter optimization.&lt;/p&gt;

&lt;h2 id=&quot;exporting-the-policy-network&quot;&gt;Exporting the Policy Network&lt;/h2&gt;

&lt;p&gt;Training a good policy is only half the work. The final objective is
to submit a solution on CodinGame. Two hurdles made it non-trivial:
Pytorch is not supported, and the submission must be shorter than 100k characters.&lt;/p&gt;

&lt;h3 id=&quot;pytorch-modules-without-pytorch&quot;&gt;Pytorch Modules without Pytorch&lt;/h3&gt;

&lt;p&gt;Since v1.7.0, Pytorch has the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fx&lt;/code&gt; subpackage which contains three components:
a symbolic tracer, an intermediate representation, and Python code generation.
By employing a symbolic tracing, you obtain a graph that can be transformed.
Finally, the last bit generates a valid code with match the graph’s semantic.&lt;/p&gt;

&lt;p&gt;Unfortunately, the code generator covers only the module’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;forward()&lt;/code&gt; method.
For the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__()&lt;/code&gt;, I wrote the code generation to traverse through
all modules and print all parameter weights. Finally, since Pytorch is unavailable
in the environment, I had to implement three Pytorch modules in pure numpy:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Sequential&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Linear&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ReLU&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The exported module is self-contained and combines both parameter weights
and a computation graph. The result looks something like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MarsLanderPolicy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;6.22188151e-02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;9.03800875e-02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.03082988&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.05894076&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;6.34499416e-02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.32812252e-02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,,&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0534077&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.02541942&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.07862598&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01890517&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.08827707&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.10649449&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;observation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;policy_net_0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;getattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;observation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;policy_net_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;getattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;policy_net_0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;policy_net_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;getattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;policy_net_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;policy_net_3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;getattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;policy_net_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;action_net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;policy_net_3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_net&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;encoding-for-shortening&quot;&gt;Encoding for Shortening&lt;/h3&gt;

&lt;p&gt;As good as it looks, the exported solution is way too long at 440k characters.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/codingame-code-too-long.png&quot; alt=&quot;Oups Submitted code is too long&quot; style=&quot;max-width:300px&quot; /&gt;
  &lt;figcaption&gt;Fig. 1 — CodinGame Error&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The model has 71 input values, two hidden layers with 128 activations and two output nodes,
which represents 25,858 free parameters. We could train a shallower network, but let’s see if
we can find a way to shrink the generated code by at least 78%.&lt;/p&gt;

&lt;p&gt;Each parameter is a 32-bit float, which takes, on average, 16 characters in plain text.
Even when truncating to float16, the exported module is only ~100k chars shorter.&lt;/p&gt;

&lt;p&gt;Clearly, printing all the floating numbers decimals is expensive.
A different representation must be used! The shortest solution is obtained by taking the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Base64&quot;&gt;base64&lt;/a&gt; encoding of the buffers filled with half float. The solution is now only 75k chars long.&lt;/p&gt;

&lt;p&gt;I had one more trick up my sleeve in case base64 had been insufficient. So far, I have only been
using chars contained in the &lt;a href=&quot;https://en.wikipedia.org/wiki/ASCII&quot;&gt;ASCII table&lt;/a&gt;. The hack is to
group two consecutive UTF-8 chars into one UTF-16 char. It’s way less readable and practical, but this yields
another 50% reduction! Look at this monstrosity:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'浩潰瑲猠獹椊灭牯⁴慭桴䜊㴠㌠㜮ㄱ圊䑉䡔㴠㜠〰ਰ䕈䝉呈㴠㌠〰ਰ⸮ ... ⸮ਮ牰湩⡴≦牻畯摮愨杮敬紩笠潲湵⡤桴畲瑳紩⤢'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'u16'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With these three techniques combined (numerical approximation, buffer encoding and text encoding)
it would have been possible to accommodate a model with 2.75 times
more learnable parameters.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;At the time of writing, with a cumulated 2,257 liters of fuel left,
this solution puts me in 225th place over 4,986 contestants.
The policy only takes between 8ms and 10ms.&lt;/p&gt;

&lt;p&gt;This project was quite fun and a great opportunity for some hands-on RL practice.
For me, the main takeaway is that RL uses the same nuts and bolts as other ML projects.
Simplify the problem, always use visualization, provide good input, and don’t expect default
hyperparameters to work on your task.&lt;/p&gt;

&lt;p&gt;Have a look at the repo (MIT license) &lt;a href=&quot;https://github.com/antoinebrl/rl-mars-lander&quot;&gt;antoinebrl/rl-mars-lander&lt;/a&gt; if you want to play the game, use the environment
or use the trained agent.&lt;/p&gt;
</description>
        
          <description>&lt;h2 id=&quot;codingame-mars-lander&quot;&gt;CodinGame Mars Lander&lt;/h2&gt;

</description>
        
        <pubDate>Sun, 06 Feb 2022 14:14:00 +0000</pubDate>
        <link>https://antoinebrl.github.io//blog/rl-mars-lander/</link>
        <guid isPermaLink="true">https://antoinebrl.github.io//blog/rl-mars-lander/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>Why isn't Active&amp;nbsp;Learning Widely Adopted?</title>
        <description>&lt;h2 id=&quot;the-promises-of-active-learning&quot;&gt;The Promises of active learning&lt;/h2&gt;

&lt;p&gt;Aside from large amounts of computational resources, deep learning models need a crazy
amount of &lt;strong&gt;labeled data&lt;/strong&gt; to learn from. Collecting data is often not a problem as
&lt;strong&gt;data is usually very abundant&lt;/strong&gt;. However, &lt;strong&gt;generating the labels is the bottleneck&lt;/strong&gt;.
This process is very tedious, expensive, and error-prone.&lt;/p&gt;

&lt;p&gt;By going back and forth between the annotation and training phase, active learning tries to
&lt;strong&gt;identify the most valuable data point for the task&lt;/strong&gt;. The model is first trained on a small
number of labeled samples. Then, it selects the unlabeled data about which
the prediction is uncertain. We say that the model formulates a query of unlabeled data.
When the annotators provide the labels (that is, the answers), the model
can be retrained on a larger dataset. The process is repeated several times until the
annotation budget expires or performances are deemed good enough. In this way,
fewer samples are required to reach the same, or superior, level of performance.
This should translate to &lt;strong&gt;faster and cheaper annotations&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;It should look something like this:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/active-learning-illustrate.svg&quot; alt=&quot;Benefit of active learning illustrated&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;The rest of this article doesn’t assume any more knowledge about active learning than
the description above. If you are interested in learning more about the different
scenarios and query strategies, I recommend reading
&lt;a href=&quot;http://burrsettles.com/pub/settles.activelearning.pdf&quot;&gt;“Active Learning Literature Survey” by Burr Settles&lt;/a&gt;
or the &lt;a href=&quot;https://en.wikipedia.org/wiki/Active_learning_(machine_learning)&quot;&gt;Wikipedia article on this topic&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;whats-wrong-with-active-learning&quot;&gt;What’s wrong with active learning?&lt;/h2&gt;

&lt;p&gt;You can find a lot of content that depicts active learning in a very flattering way.
In sharing my views on the subject, I would like to share some reasons why it’s not so
widely embraced.&lt;/p&gt;

&lt;h3 id=&quot;static-dataset-is-the-rule&quot;&gt;Static dataset is the rule&lt;/h3&gt;

&lt;p&gt;All publicly available datasets are inert. The second they become public, they
freeze: no new sample or annotation will be added or modified. This happens
for good reason: &lt;strong&gt;having a static dataset ensures a fair comparison of methods
and algorithms&lt;/strong&gt;. It leads to a sharp contrast between building the datasets and training
a model.&lt;/p&gt;

&lt;p&gt;However, in the industry, the story is completely different. &lt;strong&gt;Data continues to be generated,
and labeling is often a continuous effort&lt;/strong&gt;. As more and more code is shared
under permissive open-source licenses, the real competitive advantage comes from the size
and the quality of the datasets. I saw some large, fully annotated datasets being sold for a few
million dollars. (This dataset was then copied into a large hard drive and sent by mail
to the other side of the Earth to complete the exchange 😨.
But that’s a story for another time!)&lt;/p&gt;

&lt;p&gt;The curation process is often overlooked. It’s certainly not the sexiest part of
the job, but I believe people should talk more about it because it’s a key aspect
of the success of any machine learning project. If I were to hazard a guess, I would say for one
paper on dataset curation and creation, there are more than ten thousand papers claiming
state-of-the-art for their models.&lt;/p&gt;

&lt;h3 id=&quot;training-is-easy-evaluation-is-hard&quot;&gt;Training is easy, evaluation is hard&lt;/h3&gt;

&lt;p&gt;Training a model is great fun. Unfortunately, that’s the easy part!
&lt;strong&gt;The real struggle is performing a fair, rigorous and challenging evaluation of the predictive
capabilities of a model&lt;/strong&gt;.
It is now considered the golden rule to set aside a portion of the labeled samples
before doing any training. The goal is to understand whether the model behaves
well on unseen data. Reporting performances on the training set falls short of
the desired assessment.&lt;/p&gt;

&lt;p&gt;Given a dataset with annotations (and some rich metadata), it becomes easier to build a
representative and challenging test set before training. However, because &lt;strong&gt;active learning combines
the annotation and the training phases, it is unclear how and when the test set is built&lt;/strong&gt;.
This is often the major flaw in all publications on active learning techniques:
they rely on already well-made test sets.&lt;/p&gt;

&lt;p&gt;If you can afford to select random samples for evaluation, then you are good to go.
But, if you need stratified sampling or more challenging splits, then active
learning might not be suitable. A practical approach is to initiate the test set with random samples
and then to enlarge or rebuild it with samples from the training set when it reaches a certain size.
The test set can be modified several times over the course of the training.
However, changing the test set too often makes it hard to track learning progress.&lt;/p&gt;

&lt;h3 id=&quot;there-is-no-such-thing-as-a-free-lunch&quot;&gt;There is no such thing as a free lunch&lt;/h3&gt;

&lt;p&gt;As the adage says, nothing comes for free. &lt;strong&gt;Like any machine learning
technique, active learning requires a good amount of tuning to gain maximum performances&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The final training set should contain samples which are &lt;strong&gt;representative of
the latent distribution, as diverse as possible and as informative as possible
to solve the task&lt;/strong&gt;.
An active learning algorithm must carefully balance these three requirements.
Indeed, by focusing solely on the most representative samples, we are likely
to draw very similar items from high-density regions. Some diversity must
be enforced to cover more of the input space.
However, if we optimize for diversity, we end up with outliers or items on the
outskirt of the domain. &lt;strong&gt;A good exploration strategy is often dataset specific,
so there is no clear winner&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;strong&gt;pertinence of a sample for the task is often related to the
training dynamic of a specific model&lt;/strong&gt;. A data point might be selected because it lies
on the decision boundary of a model (high uncertainty).
However, a different model would have placed this boundary somewhere else and queried
different data points. Even worse, an item might be considered very
informative in the early steps of the process, but it might become irrelevant when new
annotations get added. &lt;strong&gt;This greedy strategy is therefore dependent on
an architecture, a given initialization, and a set of hyper-parameters&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;the-rise-of-other-training-techniques&quot;&gt;The rise of other training techniques&lt;/h3&gt;

&lt;p&gt;Another prevalent assumption in the literature is that the training
is fully supervised. Despite being the most widely used training paradigm, supervised
learning is no longer the only technique to achieve good results.&lt;/p&gt;

&lt;p&gt;The recent surge of research in unsupervised, semi-supervised, and self-supervised learning
has led to a rapidly decreasing performance gap with supervised techniques. These approaches
leverage huge amounts of unlabeled data; the more we feed them, the better they get.
&lt;strong&gt;Labeling all the samples might be impossible, but not utilizing the unlabeled
ones is a waste&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;the-low-return-on-investment&quot;&gt;The low return on investment&lt;/h3&gt;

&lt;p&gt;Active learning was invented to reduce the amount of required labeled samples.
Here, the number of annotations serves as a proxy to cut costs and time.
Yet, &lt;strong&gt;not all samples are created equal&lt;/strong&gt;. Some data points might take longer
to fully annotate, or they might require an expert eye, which is often scarce and/or expensive.
If that is the case, the dataset breaks the assumption of constant cost per sample,
which might not yield the expected gain.&lt;/p&gt;

&lt;p&gt;In addition, the benefits are minimized because active learning requires a lot
of computations. Every time a new batch of data is annotated, a new training
is initiated. This successive retraining on ever-growing datasets tends to increase drag costs.
If not considered upfront, &lt;strong&gt;the computational costs can eat all the savings
or make it more expensive than traditional annotation methods&lt;/strong&gt;. These computational
costs are not reported in academic publications.&lt;/p&gt;

&lt;p&gt;On top of this, time is no longer a constraint. &lt;strong&gt;The labeling industry
scales vertically really well&lt;/strong&gt; by hiring thousands of workers all around the world.
Suppose you retrain your model every 24h and you need to query enough data for a full day of
work for hundreds of annotators; this represents a challenge for any active learning
methods. As batches become bigger, they bring less and less information per sample.&lt;/p&gt;

&lt;p&gt;Finally, &lt;strong&gt;most of the costs induced by active learning are from implementation,
experiment tracking, version control, automation, maintenance, etc&lt;/strong&gt;.
This is referred to as MLOps and should come as no surprise as active learning
is a branch of machine learning. These operations overseen
by skilled and highly paid ML scientists and ML engineers.&lt;/p&gt;

&lt;h2 id=&quot;when-to-use-active-learning&quot;&gt;When to use active learning&lt;/h2&gt;

&lt;p&gt;This post aims to present active learning in a less romanticized way than
what you usually find in blogposts and scientific publications. Despite the numerous
limitations I listed, I still think active learning is a necessity for some projects;
however, it should not be used the way it was originally intended.&lt;/p&gt;

&lt;p&gt;In my opinion, &lt;strong&gt;active learning can’t be applied when bootstrapping a dataset&lt;/strong&gt;
to reduce cost or to speed up model release. These techniques
&lt;strong&gt;outweigh the drawbacks only when building enormous datasets at scale or when
tackling the long tail distribution of edge cases.&lt;/strong&gt; Ignoring the tail of edge cases
can be detrimental for some companies.&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;The data infrastructure comes first&lt;/h4&gt;

&lt;p&gt;As briefly discussed, the infrastructure to support fast iterations and curation of
the data is a key component for a successful data strategy. This means that the companies
must invest significantly in tooling and automation for the data pipeline.
These investments in themselves should be beneficial by speeding up delivery, reducing
human operations, etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Active learning comes into play only when the data infrastructure
is matured and mastered&lt;/strong&gt;. At this scale, active learning becomes the solution to keep
the dataset growth under control and keep infrastructure cost manageable.&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;The long tail distribution of edge cases&lt;/h4&gt;

&lt;p&gt;At first, the model attempts to build a relevant and effective representation
of the domain space. At this stage, feeding more and more data to a machine learning
model yields great improvements.&lt;/p&gt;

&lt;p&gt;But once the model has gained great generalization capabilities, it needs to handle edge cases.
By definition, edge cases are rare and difficult. This means &lt;strong&gt;the improvements get smaller
and smaller as the dataset grows&lt;/strong&gt;. This phenomenon is known as diminishing returns on data.&lt;/p&gt;

&lt;p&gt;There are two ways to tackle this problem. The first is to make the dataset
several orders of magnitude larger. The bad news is that
&lt;a href=&quot;https://ai.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html&quot;&gt;Google&lt;/a&gt;,
&lt;a href=&quot;https://engineering.fb.com/2018/05/02/ml-applications/advancing-state-of-the-art-image-recognition-with-deep-learning-on-hashtags/&quot;&gt;Facebook&lt;/a&gt;, and
&lt;a href=&quot;https://arxiv.org/abs/2104.10972&quot;&gt;Alibaba&lt;/a&gt; have found a
&lt;strong&gt;logarithmic correlation between performance and the number of annotated samples&lt;/strong&gt;.
If you have deep pockets, racks full of GPUs, and a lot of time, then this is an easy solution
to boost performance.&lt;/p&gt;

&lt;p&gt;The logarithmic relationship between the number of samples and
the performances is related to the distribution of edge cases. The real world is messy,
and therefore all machine learning problems have a long tail distribution of data
(a VERY long tail for most tasks), as illustrated below. As the number
of samples decreases, so does the performance.
A16z has a fascinating blog on this topic:
&lt;a href=&quot;https://a16z.com/2020/08/12/taming-the-tail-adventures-in-improving-ai-economics/&quot;&gt;Taming the Tail: Adventures in Improving AI Economics&lt;/a&gt;.
The takeaway is that, to tackle the long tail
distribution, one should optimize the model, narrow down the problem, and
obtain more data from customers.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/long-tail-distribution.svg&quot; alt=&quot;Long tail distribution illustration&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;Another solution is to &lt;strong&gt;be more selective when building the training set&lt;/strong&gt;.
The goal is to change the prevalence of observations through a careful selection.
Rather than including all possible data points and hoping for the best, it’s time
to optimize for the quality of samples. This is where active learning thrives!
It helps identify underrepresented cases where the model struggles,
and it discards samples related to already learned concepts.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Active learning is often presented as a way to help bootstrap a dataset.
In my opinion, active learning and other sophisticated means of data curation
should be used only during a later stage when the data pipeline is already quite advanced.
&lt;strong&gt;Active learning is as much of an engineering solution for dataset scaling as it is
a machine learning technique to chase the last few points of accuracy&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;These techniques should identify gaps in the datasets, balance data distribution, and
most importantly close the feedback loop. With active learning, it becomes easier to
identify the failure modes of the model. This assessment provides insights
into the exploration and curation of the data, and finally, results in ad hoc rules for adding
specific samples to the training set. Being proactive in the discovery of infrequent
samples is paramount for most real-world applications such as self-driving cars
and healthcare.&lt;/p&gt;

&lt;h2 id=&quot;related-readings&quot;&gt;Related Readings&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.waymo.com/2020/02/content-search.html&quot;&gt;Waymo Blog - Seeing is Knowing: Advances in search and image recognition train Waymo’s self-driving technology for any encounter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=g6bOwQdCJrc&quot;&gt;Andrej Karpathy’s (Tesla) talk at CVPR’21 - Workshop on autonomous driving&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/cruise/cruise-continuous-learning-machine-30d60f4c691b&quot;&gt;Cruise’s Continuous Learning Machine Predicts the Unpredictable on San Francisco Roads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        
          <description>&lt;h2 id=&quot;the-promises-of-active-learning&quot;&gt;The Promises of active learning&lt;/h2&gt;

</description>
        
        <pubDate>Sun, 26 Sep 2021 10:12:00 +0000</pubDate>
        <link>https://antoinebrl.github.io//blog/active-learning/</link>
        <guid isPermaLink="true">https://antoinebrl.github.io//blog/active-learning/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>Relationship Between Machine Learning Methods</title>
        <description>&lt;p&gt;Back when I was doing my master in Data Science and Cognitive Systems at KTH I had an 
interesting conversion about the number of algorithms a data scientist should know to do his work.
My friend was baffled by the number of techniques that we had to learn for the exams.
As a rather lazy student, I was a bit perplex too. The truth is that many methods and tricks can be used
within widely different models.&lt;/p&gt;

&lt;p&gt;In that regard, data science is a bit like cooking. Data scientists know some algorithms like a
chef know some recipes. Both of them can follow the step-by-step instructions to complete the job.
However, 3 Michellin-starred chefs not only know many recipes, but they understand how to combine ingredients
and techniques to create new flavours and textures. In the same way, good data scientists can combine
methods and techniques to create different models and boost performances.&lt;/p&gt;

&lt;p&gt;With this in mind, let’s look at how some models relate.
For example, all models can be used for both classification and regression with a slight modification
to the computed output or the final voting. Another interesting example is to think of
gaussian processes as linear regression with the kernel method under a Bayesian framework.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/model-relationship.svg&quot; alt=&quot;Statistical model relationship&quot; style=&quot;max-width:680px&quot; /&gt;
  &lt;figcaption&gt;Fig. 1 — Statistical Model Relationship.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The figure above is a small representation of the relationship between machine learning models.
It is far from being exhaustive as it would rapidly get very messy. For instance, the kernel method is
a core element of &lt;em&gt;support vector machines (SVM)&lt;/em&gt; but can also be used with &lt;em&gt;k-nearest neighbours (k-NN)&lt;/em&gt;.
Both of them can be used for classification and regression tasks.&lt;/p&gt;

&lt;p&gt;Throwing data to an algorithm is not enough. Understanding how statistical methods relate is key
to designing efficient machine learning models and data pipelines.&lt;/p&gt;

&lt;p&gt;PS: Here is a small exercise for the reader: among the models in Fig.1 above, which are parametric and non-parametric?&lt;/p&gt;
</description>
        
          <description>&lt;p&gt;Back when I was doing my master in Data Science and Cognitive Systems at KTH I had an 
interesting conversion about the number of algorithms a data scientist should know to do his work.
My friend was baffled by the number of techniques that we had to learn for the exams.
As a rather lazy student, I was a bit perplex too. The truth is that many methods and tricks can be used
within widely different models.&lt;/p&gt;

</description>
        
        <pubDate>Sun, 21 Mar 2021 10:36:00 +0000</pubDate>
        <link>https://antoinebrl.github.io//blog/model-relationship/</link>
        <guid isPermaLink="true">https://antoinebrl.github.io//blog/model-relationship/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>K-Nearest Neighbors (KNN) - Visualizing the Variance</title>
        <description>&lt;p&gt;In chapter 2 of &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;,
the authors compare least square regression and nearest neighbors in terms of bias and variance.
I thought it would be interesting to have an interactive visualization to understand
why k-NN is said to have low bias and high variance.&lt;/p&gt;

&lt;p&gt;Section 2.5 starts like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The linear decision boundary from least squares is very smooth, and apparently stable to fit. It does appear to rely heavily on the assumption that a linear decision boundary is appropriate. […] It has low variance and bigh bias.
&lt;br /&gt; On the other hand, the &lt;em&gt;k-nearest-neighbor&lt;/em&gt; procedures do not appear to rely on any stringent assumptions about the underlying data, and can adapt to any situation. However, any particular subregion of the decision boundary depends on a handful of input points and their particular positions, and is thus wiggly and unstable–high variance and low bias.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For this example, we use k-NN in the context of binary classification where the assignment
is determined by the majority in the voting process. The distance used is the Euclidean distance.&lt;/p&gt;

&lt;p&gt;The visualization is interactive. You can:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;adjust the number of neighbors (k) to incorporate in the voting process.&lt;/li&gt;
  &lt;li&gt;flip the class of a data point by clicking on it,&lt;/li&gt;
  &lt;li&gt;move your mouse to see the nearest neighbors. On mobile, you can also tap anywhere,&lt;/li&gt;
  &lt;li&gt;grad a data point and place it wherever you want.
It’s possible that on mobile the drag interfere with the scroll. The trick is to tap, stay in place
a fraction of a second and only then move the finger.
If you are on mobile, I recommend you increase the radius parameter,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Have some fun!&lt;/p&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;1040&quot; frameborder=&quot;0&quot; src=&quot;https://observablehq.com/embed/@antoinebrl/knn-visualizing-the-variance?cells=viewof+k%2Cviewof+n%2Cviewof+radius%2Cviewof+boundary_cell_size%2Cchart%2Cstyle&quot;&gt;&lt;/iframe&gt;
</description>
        
          <description>&lt;p&gt;In chapter 2 of &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;,
the authors compare least square regression and nearest neighbors in terms of bias and variance.
I thought it would be interesting to have an interactive visualization to understand
why k-NN is said to have low bias and high variance.&lt;/p&gt;

</description>
        
        <pubDate>Fri, 12 Feb 2021 18:25:00 +0000</pubDate>
        <link>https://antoinebrl.github.io//blog/knn-variance/</link>
        <guid isPermaLink="true">https://antoinebrl.github.io//blog/knn-variance/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>Deep (Deep, Deep) Dive into K-Means Clustering</title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax = {
  loader: {load: ['[tex]/color']},
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)'], ['\\[', '\\]']],
    packages: {'[+]': ['color']}
  },
  svg: {
    fontCache: 'glo\(( bal',
    linebreak: 
      automatic: true
  }
};
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://d3js.org/d3.v6.min.js&quot;&gt;&lt;/script&gt;

&lt;style&gt;
.MathJax {
  overflow-x:auto;
}
svg.animation {
  box-shadow: 0 10px 16px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19) !important;
}
figure {
  text-align: center;
  margin: 0.5rem auto 2rem auto !important;
}
&lt;/style&gt;

&lt;h2 class=&quot;no_toc&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Clustering is the task of grouping similar-looking data points into subsets&lt;/strong&gt;.
Such a group is called a cluster.
Data points within the same cluster should look alike or share similar
properties compared to items in other clusters.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Clustering is an &lt;a href=&quot;https://en.wikipedia.org/wiki/Unsupervised_learning&quot;&gt;unsupervised learning&lt;/a&gt; technique&lt;/strong&gt;
mainly used for data exploration, data mining, and information compression through quantization.
All clustering algorithms have to find patterns in the data by themselves, as it comes without any labels.
The consequence is that the notion of a “good cluster” depends on the use case and is somewhat subjective.
Over the years, this has led to the development of hundreds of algorithms, each with
their own merits and drawbacks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;K-means&lt;/em&gt; is a centroid model&lt;/strong&gt; -each cluster is represented by a central point.
“K” represents the number of clusters, and “mean” is the aggregation operation
applied to elements of a cluster to define the central location. 
&lt;strong&gt;Central points are called &lt;em&gt;centroids&lt;/em&gt; or &lt;em&gt;prototypes&lt;/em&gt; of the clusters&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/voronoi_k3.png&quot; alt=&quot;Voronoi cells, k=3&quot; style=&quot;max-width:300px&quot; /&gt;
  &lt;figcaption&gt;Fig. 1 — Illustration of centroid clustering.
	&lt;br /&gt;Black dots represent data points, coloured dots are centroids,
	&lt;br /&gt;and coloured areas show cluster expansions.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;the-k-means-algorithm&quot;&gt;The &lt;em&gt;K-Means&lt;/em&gt; Algorithm&lt;/h2&gt;

&lt;p&gt;From a theoretical perspective, finding the optimal solution for a clustering problem
is particularly difficult (NP-hard). Thus, &lt;strong&gt;all algorithms are only approximations
of the optimal solution&lt;/strong&gt;. The &lt;em&gt;k-means&lt;/em&gt; algorithm, sometimes referred to as the Lloyd
algorithm after its author &lt;a class=&quot;citation&quot; href=&quot;#lloyd1982least&quot;&gt;(Lloyd, 1982)&lt;/a&gt;,
is an &lt;strong&gt;iterative process that refines the solution until it
converges to a local optimum&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let’s use some mathematical notations to formalize this:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\( X = \{ \textbf{x}_1, \, \ldots ,\; \textbf{x}_n ;\, \textbf{x}_j \in \mathbb{R}^d \} \)
denotes the set of data points of dimensions \( d \).&lt;/li&gt;
  &lt;li&gt;\( C = \{ \textbf{c}_1, \, \ldots ,\; \textbf{c}_k ;\, \textbf{c}_i \in \mathbb{R}^d \} \)
is the set of centroids.&lt;/li&gt;
  &lt;li&gt;\( S = \{ S_1, \, \ldots ,\, S_k \} \) represents the groupings where \( S_i \)
is the set of data points contained in the cluster \( i \). The number of samples in \( S_i \) is noted \( n_i \).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notations can have superscripts to illustrate the iterative aspect of the algorithm.
For example, \( C^t = \{ \textbf{c}^t_1,\,  … ,\, \textbf{c}^t_k \} \) defines the centroids at step \( t \).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Given some data points and the number of clusters,
the goal is to find the optimal centroids —those which minimize the within-cluster distance—
also called the within-cluster sum squared error (SSE)&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;\[ C_{best} = \underset{C}{\arg\min}  \sum_{i=1}^{k} \sum_{\textbf{x} \in S_i} \lVert \textbf{x} - \textbf{c}_i \rVert^2 \]&lt;/p&gt;

&lt;p&gt;The training procedure is as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Initialization&lt;/strong&gt;:
Often, there is no good prior knowledge about the location of the centroids.
An effortless way to start is to define the centroids by randomly selecting
\( k \) data points from the dataset (Forgy method).
&lt;br /&gt;In mathematical notation, we define \( C^0 \), the initial set of centroids,
as a subset of data points with a cardinality of \( k \):
\( C^0 \subset X \) with \( \vert C^0 \vert = k \).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Assignment&lt;/strong&gt;:
For each data point, the distance to all centroids is computed.
The data points belong to the cluster represented by the closest centroid.
This is called a &lt;strong&gt;&lt;em&gt;hard assignment&lt;/em&gt; because the data point belongs to one and only one cluster&lt;/strong&gt;.
&lt;br /&gt;Data points are assigned to partitions as follows:
\[ S^t_i = \{\textbf{x} \in X  ;\; \lVert \textbf{x} - \textbf{c}_i \rVert &amp;lt; \lVert \textbf{x} - \textbf{c}_j \rVert, \; \forall 1 \leq j \leq k \} \]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;:
Given all the points assigned to a cluster, the mean position is computed
and defines the new location of the centroid. All centroids are updated simultaneously.
\[ \forall 1\le i \le k, \,\, \textbf{c}^{t+1}_i = \frac{1}{\vert S^t_i \vert } \sum_{\textbf{x} \in S^t_i}{\textbf{x}} \]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Repeat steps 2 and 3 until convergence&lt;/strong&gt;.
The algorithm can stop after a predefined number of iterations.
Another convergence criterion could be to stop whenever
the centroids move less than a certain threshold during step 3.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once the algorithm has converged and is used on new data, only the assignment step is
performed.&lt;/p&gt;

&lt;h2 id=&quot;visualization&quot;&gt;Visualization&lt;/h2&gt;
&lt;hr /&gt;

&lt;div&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    Number of clusters \(k\): 
    &lt;input type=&quot;number&quot; id=&quot;nb-clusters&quot; value=&quot;3&quot; min=&quot;1&quot; style=&quot;width:100px;&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;text-align: center;margin-bottom: 2rem;&quot;&gt;
  &lt;img id=&quot;data-0&quot; src=&quot;/assets/img/data0.png&quot; alt=&quot;data 0&quot; style=&quot;width:100px;height:100px;box-shadow: 0 3px 6px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);margin-bottom:0&quot; /&gt;
  &lt;img id=&quot;data-1&quot; src=&quot;/assets/img/data1.png&quot; alt=&quot;data 0&quot; style=&quot;width:100px;height:100px;box-shadow: 0 3px 6px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);margin-bottom:0&quot; /&gt;
  &lt;img id=&quot;data-2&quot; src=&quot;/assets/img/data2.png&quot; alt=&quot;data 0&quot; style=&quot;width:100px;height:100px;box-shadow: 0 3px 6px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);margin-bottom:0&quot; /&gt;
  &lt;img id=&quot;data-3&quot; src=&quot;/assets/img/data3.png&quot; alt=&quot;data 0&quot; style=&quot;width:100px;height:100px;box-shadow: 0 3px 6px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);margin-bottom:0&quot; /&gt;
  &lt;img id=&quot;data-4&quot; src=&quot;/assets/img/data4.png&quot; alt=&quot;data 0&quot; style=&quot;width:100px;height:100px;box-shadow: 0 3px 6px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);margin-bottom:0&quot; /&gt;
  &lt;img id=&quot;data-5&quot; src=&quot;/assets/img/data5.png&quot; alt=&quot;data 0&quot; style=&quot;width:100px;height:100px;box-shadow: 0 3px 6px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);margin-bottom:0&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;button id=&quot;btn-run&quot; class=&quot;button__outline&quot;&gt;Run 10 iterations&lt;/button&gt;
&lt;/div&gt;
&lt;div id=&quot;container&quot; style=&quot;text-align: center;&quot;&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;script language=&quot;javascript&quot;&gt;

// Transform 2-D standard normal data
function sample2DNormal(mu, sig){
    // Perform Cholesky decomposition$primary
    const a = Math.sqrt(sig[0][0]);
    const b = sig[0][1] / a;
    const c = Math.sqrt(sig[1][1] - b * b);
    const sqrtSig = [[a, 0], [b, c]];

    // Get random point
    const stdNorm = d3.randomNormal(0, 1);
    const u = [stdNorm(), stdNorm()];

    // Transform
    const v = {};
    v.x = mu[0] + sqrtSig[0][0] * u[0] + sqrtSig[0][1] * u[1];
    v.y = mu[1] + sqrtSig[1][0] * u[0] + sqrtSig[1][1] * u[1];

    return v;
}

function l2dist(a, b) {
    const dx = b.x - a.x;
    const dy = b.y - a.y;
    return Math.sqrt(Math.pow(dx, 2) + Math.pow(dy, 2));
}

function findClosestCentroid(point, centroids) {
    let closest = {i: -1, distance: 100000};
    centroids.forEach(function(d, i) {
        const distance = l2dist(d, point);
        if (distance &lt; closest.distance) {
            closest.i = i;
            closest.distance = distance;
        }
    });
    return closest.i;
}

const w = 320;
const h = 320;
const pad = 5;
let k = 3;
let iter = -1;

// Define plot scale
const xScale = d3.scaleLinear()
    .domain([-10, 10])
    .range([pad, w-pad]);
const yScale = d3.scaleLinear()
    .domain([-10, 10])
    .range([pad, h-pad]);

const svg = d3.select(&quot;#container&quot;)
  .append(&quot;svg&quot;)
  .attr(&quot;class&quot;, &quot;animation&quot;)
  .attr(&quot;width&quot;, w)
  .attr(&quot;height&quot;, h)
  .style(&quot;text-align&quot;, &quot;center&quot;);

d3.select(&quot;#nb-clusters&quot;).attr(&quot;value&quot;, k).on(&quot;input&quot;, function() {
    while (this.value &lt; k) {
        centroids.pop();
        k = k - 1;
    }
    if (this.value &gt; k) {
        centroids = centroids.concat(select_centroids(data, this.value - k));
        k = this.value;
    }
    svg.selectAll(&quot;.centroid&quot;)
        .data(centroids)
        .exit()
        .remove();
    draw_centroids(centroids);
    if (iter == 0) {
        iter = 10;
        start();
    }
})

function draw_data(data) {
    const d = svg.selectAll(&quot;.data&quot;).data(data)
    d.exit()
     .transition()
     .duration(100)
     .attr(&quot;r&quot;, 0)
    d.enter()
     .append(&quot;circle&quot;)
     .merge(d)
     .attr(&quot;class&quot;, &quot;data&quot;)
     .attr(&quot;cx&quot;, d =&gt; d.x)
     .attr(&quot;cy&quot;, d =&gt; d.y)
     .attr(&quot;r&quot;, 0)
     .transition()
     .duration(150)
     .attr(&quot;r&quot;, 4)
     .transition()
     .duration(150)
     .attr(&quot;r&quot;, 3)
}

let data = []

d3.select(&quot;#data-0&quot;).on(&quot;click&quot;, function() {
    let points = []
    points = points.concat(d3.range(80).map(function() {
        return sample2DNormal([-5, -5], [[4, 0], [0, 4]]);
    }));
    points = points.concat(d3.range(80).map(function() {
        return sample2DNormal([5, 5], [[4, 0], [0, 4]]);
    }));
    points = points.concat(d3.range(80).map(function() {
        return sample2DNormal([5, -5], [[4, 0], [0, 4]]);
    }));
    points = points.concat(d3.range(80).map(function() {
        return sample2DNormal([-5, 5], [[4, 0], [0, 4]]);
    }));
    data = points.map(d =&gt; ({x: xScale(d.x), y: yScale(d.y)}));
    remove_visual_annotations();
    draw_data(data);
    if (iter == 0) {
        iter = 10;
        start();
    }
}).dispatch('click');

//d3.select(&quot;#data-1&quot;).on(&quot;click&quot;, function() {
//    let points = []
//    points = points.concat(d3.range(50).map(i =&gt; sample2DNormal([-3, -3], [[3, -2], [-2, 3]])));
//    points = points.concat(d3.range(50).map(i =&gt; sample2DNormal([ 5, -2], [[2, -1], [-1, 2]])));
//    points = points.concat(d3.range(50).map(i =&gt; sample2DNormal([ 0,  3], [[2,  0], [ 0, 2]])));
//    data = points.map(d =&gt; ({x: xScale(d.x), y: yScale(d.y)}));
//    draw_data(data);
//    if (iter == 0) {
//        iter = 10;
//        start();
//    }
//});
d3.select(&quot;#data-1&quot;).on(&quot;click&quot;, function() {
    let points = []
    points = points.concat(d3.range(80).map(function() {
        return sample2DNormal([-5.5, 0], [[0.2, 0], [0, 7]]);
    }));
    points = points.concat(d3.range(80).map(function() {
        return sample2DNormal([1.5, 0], [[7, 0], [0, 0.2]]);
    }));
    data = points.map(d =&gt; ({x: xScale(d.x), y: yScale(d.y)}));
    remove_visual_annotations();
    draw_data(data);
    if (iter == 0) {
        iter = 10;
        start();
    }
});

d3.select(&quot;#data-2&quot;).on(&quot;click&quot;, function() {
    let points = []
    points = points.concat(d3.range(90).map(function(i) {
        noise = sample2DNormal([0,0], [[0.15, 0], [0, 0.15]]);
        const r = 7;
        const rad = i * 4 / 180 * Math.PI;
        return { x: r * Math.cos(rad) + noise.x, y : r * Math.sin(rad) + noise.y} 
    }));
    points = points.concat(d3.range(20).map(i =&gt; sample2DNormal([-2, -1.75], [[0.5, 0], [0, 0.5]])));
    points = points.concat(d3.range(20).map(i =&gt; sample2DNormal([2, -1.75], [[0.5, 0], [0, 0.5]])));
    points = points.concat(d3.range(30).map(function(i) {
        noise = sample2DNormal([0,0], [[0.15, 0], [0, 0.15]]);
        const r = 3.5;
        const rad = i * 4 / 180 * Math.PI + Math.PI / 6;
        return { x: r * Math.cos(rad) + noise.x, y : r * Math.sin(rad) + noise.y} 
    }));
    data = points.map(d =&gt; ({x: xScale(d.x), y: yScale(d.y)}));
    remove_visual_annotations();
    draw_data(data);
    if (iter == 0) {
        iter = 10;
        start();
    }
});

d3.select(&quot;#data-3&quot;).on(&quot;click&quot;, function() {
    let points = []
    points = points.concat(d3.range(90).map(function(i) {
        noise = sample2DNormal([0,0], [[0.15, 0], [0, 0.15]]);
        const r = 7;
        const rad = i * 4 / 180 * Math.PI;
        return { x: r * Math.cos(rad) + noise.x, y : r * Math.sin(rad) + noise.y} 
    }));
    points = points.concat(d3.range(45).map(function(i) {
        noise = sample2DNormal([0,0], [[0.15, 0], [0, 0.15]]);
        const r = 3;
        const rad = i * 8 / 180 * Math.PI;
        return { x: r * Math.cos(rad) + noise.x, y : r * Math.sin(rad) + noise.y} 
    }));
    data = points.map(d =&gt; ({x: xScale(d.x), y: yScale(d.y)}));
    remove_visual_annotations();
    draw_data(data);
    if (iter == 0) {
        iter = 10;
        start();
    }
});


d3.select(&quot;#data-4&quot;).on(&quot;click&quot;, function() {
    let points = []
    points = points.concat(d3.range(45).map(function(i) {
        noise = sample2DNormal([-2.75,-1], [[0.15, 0], [0, 0.30]]);
        const r = 6;
        const rad = i * 4 / 180 * Math.PI;
        return { x: r * Math.cos(rad) + noise.x, y : r * Math.sin(rad) + noise.y} 
    }));
    points = points.concat(d3.range(45).map(function(i) {
        noise = sample2DNormal([2.75,1], [[0.15, 0], [0, 0.30]]);
        const r = 6;
        const rad = i * 4 / 180 * Math.PI + Math.PI;
        return { x: r * Math.cos(rad) + noise.x, y : r * Math.sin(rad) + noise.y} 
    })); 
    data = points.map(d =&gt; ({x: xScale(d.x), y: yScale(d.y)}));
    remove_visual_annotations();
    draw_data(data);
    if (iter == 0) {
        iter = 10;
        start();
    }
});


d3.select(&quot;#data-5&quot;).on(&quot;click&quot;, function() {
    let points = []
    points = points.concat(d3.range(60).map(function(i) {
        return {x: d3.randomUniform(-2, 2)(), y: d3.randomUniform(-2, 2)()}
    }).filter(
        d =&gt; Math.sqrt(d.x * d.x + d.y * d.y) &lt; 2
    ).map(
        d =&gt; ({x: d.x + 5, y: d.y - 4})
    ));
    points = points.concat(d3.range(60).map(function(i) {
        return {x: d3.randomUniform(-2, 2)(), y: d3.randomUniform(-2, 2)()}
    }).filter(
        d =&gt; Math.sqrt(d.x * d.x + d.y * d.y) &lt; 2
    ).map(
        d =&gt; ({x: d.x - 5, y: d.y - 4})
    ));
    points = points.concat(d3.range(200).map(function(i) {
        return {x: d3.randomUniform(-5, 5)(), y: d3.randomUniform(-5, 5)() + 1}
    }).filter(
        d =&gt; Math.sqrt(d.x * d.x + d.y * d.y) &lt; 5
    ).map(
        d =&gt; ({x: d.x, y: d.y + 1})
    ));
    data = points.map(d =&gt; ({x: xScale(d.x), y: yScale(d.y)}));
    remove_visual_annotations();
    draw_data(data);
    if (iter == 0) {
        iter = 10;
        start();
    }
});



function draw_centroids(centroids) {
    svg.selectAll(&quot;.centroid&quot;)
        .data(centroids)
        .enter()
        .append(&quot;circle&quot;)
        .attr(&quot;class&quot;, &quot;centroid&quot;)
        .attr(&quot;cx&quot;, d =&gt; d.x)
        .attr(&quot;cy&quot;, d =&gt; d.y)
        .style(&quot;fill&quot;, (d, i) =&gt; colors(i))
        .style(&quot;stroke&quot;, &quot;black&quot;)
        .style(&quot;stroke-width&quot;, 2)
        .attr(&quot;r&quot;, 0)
        .transition()
        .duration(150)
        .attr(&quot;r&quot;, 8)
        .transition()
        .duration(150)
        .attr(&quot;r&quot;, 6);
}

function draw_cluster_assignment(data) {
    svg.selectAll(&quot;.line&quot;)
        .data(data)
        .enter()
        .append(&quot;line&quot;)
        .attr(&quot;class&quot;, &quot;line&quot;)
        .attr(&quot;x1&quot;, d =&gt; d.x)
        .attr(&quot;y1&quot;, d =&gt; d.y)
        .attr(&quot;x2&quot;, d =&gt; d.x)
        .attr(&quot;y2&quot;, d =&gt; d.y)
        .style(&quot;stroke&quot;, d =&gt; colors(d.cluster))
        .style(&quot;stroke-opacity&quot;, 0.4)
        .transition()
        .delay(d =&gt; Math.random() * 500)
        .duration(300)
        .attr(&quot;x2&quot;, d =&gt; centroids[d.cluster].x)
        .attr(&quot;y2&quot;, d =&gt; centroids[d.cluster].y)

    svg.selectAll(&quot;.data&quot;)
        .transition()
        .delay(d =&gt; Math.random() * 500)
        .duration(100)
        .style(&quot;fill&quot;, (d, i) =&gt; colors(d.cluster));
}

function draw_centroids_update(new_centroids) {
    svg.selectAll(&quot;.centroid&quot;)
       .data(new_centroids)
       .transition()
       .delay(750)
       .duration(500)
       .attr(&quot;cx&quot;, d =&gt; d.x)
       .attr(&quot;cy&quot;, d =&gt; d.y)

    svg.selectAll(&quot;.line&quot;)
       .data(data)
       .transition()
       .delay(750)
       .duration(500)
       .attr(&quot;x2&quot;, d =&gt; new_centroids[d.cluster].x)
       .attr(&quot;y2&quot;, d =&gt; new_centroids[d.cluster].y)
}

function remove_visual_annotations() {
    svg.selectAll(&quot;.line&quot;)
       .data(data)
       .transition()
       .delay(1500)
       .style(&quot;stroke-opacity&quot;, 0)
       .remove()

    svg.selectAll(&quot;.data&quot;)
       .data(data)
       .transition()
       .delay(1500)
       .style(&quot;fill&quot;, &quot;black&quot;)

}

function select_centroids(data, k) {
    return d3.range(k).map(function() {return data[Math.floor(Math.random() * data.length)]});
}

function assign_cluster(data, centroids) {
    data.forEach(d =&gt; d.cluster = findClosestCentroid(d, centroids));
}

function compute_centroids(k) {
    centroids = d3.range(k).map(function(i) {
        const points_in_cluster = data.filter(d =&gt; d.cluster == i)
        return {
          x: d3.mean(points_in_cluster.map(d =&gt; d.x)),
          y: d3.mean(points_in_cluster.map(d =&gt; d.y))
        };
    });
    return centroids;
}

var colors = d3.scaleOrdinal().domain(d3.range(k)).range(d3.schemeCategory10);
let centroids = [];
draw_data(data, svg);

play_layer = svg.append(&quot;g&quot;); 
play_layer.append(&quot;rect&quot;)
  .attr(&quot;width&quot;, &quot;100%&quot;)
  .attr(&quot;height&quot;, &quot;100%&quot;)
  .attr(&quot;fill&quot;, &quot;white&quot;)
  .attr(&quot;fill-opacity&quot;, 0.5)
play_layer.append(&quot;path&quot;)
  .attr(&quot;d&quot;, d3.symbol().type(d3.symbolTriangle).size(4000))
  .attr(&quot;fill&quot;, &quot;black&quot;)
  .attr(&quot;transform&quot;, function(d) { 
    return &quot;rotate(-30) translate(50, 200)&quot;;
  });

function animate() {
    const delaunay = d3.Delaunay.from(centroids, d =&gt; d.x, d =&gt; d.y);
    const voronoi = delaunay.voronoi([0, 0, w, h]);
    let v = svg.selectAll(&quot;.voronoi&quot;)
        .data(centroids);
    v.enter()
        .append(&quot;path&quot;)
        .attr(&quot;class&quot;, &quot;voronoi&quot;)
        .attr(&quot;d&quot;, (d, i) =&gt; voronoi.renderCell(i))
        .attr(&quot;fill-opacity&quot;, 0.25)
        .attr(&quot;fill&quot;, (d, i) =&gt; colors(i))
        .attr(&quot;stroke&quot;, &quot;white&quot;)
        .attr(&quot;stroke-width&quot;, 0.5);
    v.exit().remove();
    v.transition()
        .duration(1000)
        .attr(&quot;d&quot;, (d, i) =&gt; voronoi.renderCell(i))

    assign_cluster(data, centroids);
    draw_cluster_assignment(data);
    centroids = compute_centroids(k);
    draw_centroids_update(centroids);
    remove_visual_annotations();
    iter = iter - 1;
    if (iter &gt; 0) {
        svg.transition().delay(2000).on(&quot;start&quot;, animate);
    }
}

function start(){
    iter = 10;
    play_layer.remove()
    if (centroids.length == 0){
        centroids = select_centroids(data, k);
    }
    draw_centroids(centroids, svg);
    animate()
};
svg.on(&quot;click&quot;, start);
d3.select(&quot;#btn-run&quot;).on(&quot;click&quot;, start);
&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;
It is possible to visualize the decision boundaries.
To do so, we can generalize the definitions of the groups and include all possible elements rather than
only observed data points:
\[ S_i = \{\textbf{x} \in \mathbb{R}^d  ;\; ||\textbf{x} - \textbf{c}_i || &amp;lt; || \textbf{x} - \textbf{c}_j ||, \; \forall 1 \le j \le k \} \]
These are called &lt;a href=&quot;https://en.wikipedia.org/wiki/Voronoi_diagram&quot;&gt;Voronoi cells&lt;/a&gt;, and they look like this:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/img/voronoi_k2.png&quot; alt=&quot;Voronoi cells, k=2&quot; style=&quot;max-width:300px;display:inline-block;width:32%;&quot; /&gt;
  &lt;img src=&quot;/assets/img/voronoi_k3.png&quot; alt=&quot;Voronoi cells, k=3&quot; style=&quot;max-width:300px;display:inline-block;width:32%;&quot; /&gt;
  &lt;img src=&quot;/assets/img/voronoi_k5.png&quot; alt=&quot;Voronoi cells, k=5&quot; style=&quot;max-width:300px;display:inline-block;width:32%;position: center;&quot; /&gt;
  &lt;figcaption&gt;Fig. 2 - Voronoi cells with k=2 (left), k=3 (middle) and k=5 (right).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;python-implementation-using-numpy&quot;&gt;Python Implementation using Numpy&lt;/h2&gt;

&lt;p&gt;Although the algorithm could be implemented with plenty of nested for loops,
it can execute several orders of magnitude faster if we leverage matrix arithmetic.
Numpy &lt;a class=&quot;citation&quot; href=&quot;#harris2020array&quot;&gt;(Harris et al., 2020)&lt;/a&gt; is an &lt;a href=&quot;https://numpy.org/&quot;&gt;open-source Python library&lt;/a&gt;
designed to ease the manipulation of vectors, matrices and arrays of any dimension.
The core operations are written in C, a low-level language, to achieve fast runtime.&lt;/p&gt;

&lt;p&gt;You can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conda&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip&lt;/code&gt; package managers to install Numpy.
&lt;br /&gt; conda: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conda install numpy&lt;/code&gt;
&lt;br /&gt; pip: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install numpy&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Let’s start by importing Numpy and creating some synthetic data generated from three normal distributions.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;blob1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;blob2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;blob3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blob1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blob2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blob3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The next step is to define a function for each step of the algorithm.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pick_centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;indexes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indexes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;assign_cluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Pairwise squared L2 distances. Shape [n, k]
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newaxis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# find closest centroid index. Shape [n]
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Mean positions of data within clusters
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The final step is to glue everything together inside a class:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KMeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pick_centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assign_cluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assign_cluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, we can instantiate an object, train it, and do the predictions.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KMeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you have Matplotlib installed (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install matplotlib&lt;/code&gt;), you can visualize the data and the result.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Plot data points with cluster id as color
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Plot centroids
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centroids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You should have something looking like this:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/matplotlib.png&quot; alt=&quot;Matplotlib display&quot; style=&quot;max-width:350px;display:inline-block;width:90%;&quot; /&gt;
  &lt;figcaption&gt;Fig. 3 — Matplotlib cluster visualization&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Go ahead and run the code step by step to build a better grasp of Numpy.
Read the &lt;a href=&quot;https://numpy.org/doc/stable/user/basics.broadcasting.html&quot;&gt;Numpy documentation about broadcasting operations&lt;/a&gt;
to understand how the pairwise distance is computed with a single line of code.&lt;/p&gt;

&lt;p&gt;I suggest you don’t use this code if it’s not for educational purposes. Scikit-learn &lt;a class=&quot;citation&quot; href=&quot;#scikit-learn&quot;&gt;(Pedregosa et al., 2011)&lt;/a&gt;
is a very popular &lt;a href=&quot;https://scikit-learn.org/stable/&quot;&gt;open-source Python library&lt;/a&gt;, built on top of Numpy,
which implements &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html?highlight=k%20means#sklearn.cluster.KMeans&quot;&gt;the naive k-means algorithm&lt;/a&gt;,
its variants, and many more machine learning algorithms.&lt;/p&gt;

&lt;h2 id=&quot;limitations-and-variants&quot;&gt;Limitations and Variants&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;The strength of &lt;em&gt;K-means&lt;/em&gt; is its conceptual simplicity&lt;/strong&gt;. The logic —but also the implementation—
is intuitive and straightforward. However, it is necessary to understand
that the algorithm was built around restrictive hypotheses about the data
distribution. Some tweaks and variants overcome some limitations.&lt;/p&gt;

&lt;h3 id=&quot;sensitivity-to-initialization&quot;&gt;Sensitivity to Initialization&lt;/h3&gt;

&lt;p&gt;The first drawback of k-means, which can easily be observed after a few runs, is the sensitivity
of the algorithm to the initial locations of the centroids.
&lt;strong&gt;Each possible initialization corresponds to a certain convergence speed and a final solution&lt;/strong&gt;.
Some solutions correspond to local minima and are far from optimal.&lt;/p&gt;

&lt;p&gt;A naive way to address this sensitivity to initialization is to run the algorithm several
times and keep the best model. Another solution to get around it is to use expert knowledge
to hand-craft what could be a good initialization. A third solution is to &lt;strong&gt;come up with
some heuristics to define a good initialization state. These rules are called &lt;em&gt;seeding techniques&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Seeding techniques&lt;/h4&gt;

&lt;p&gt;Many seeding heuristics have been developed over time.
&lt;em&gt;K-means++&lt;/em&gt; &lt;a class=&quot;citation&quot; href=&quot;#arthur2006k&quot;&gt;(Arthur &amp;amp; Vassilvitskii, 2006)&lt;/a&gt; is one of the most popular
and the default initialization method in Scikit-learn (and Matlab).
The motivation behind it is that &lt;strong&gt;spreading out the initial centroids
is beneficial&lt;/strong&gt;. Indeed, picking up spread centroids increases the chances
that they belong in different clusters.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;k-means++&lt;/em&gt; seeding algorithm is as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Randomly select the first set of centroids among the data points.&lt;/li&gt;
  &lt;li&gt;For all data points, compute the distance to the closest centroid \( D(\textbf{x}) \).&lt;/li&gt;
  &lt;li&gt;Pick up another centroid from the set of data points, given the weighted
distribution proportional to the squared
distances: \( p(\textbf{x}_i)= \frac{ D(\textbf{x}_i)^2 }{ \sum_{\textbf{x} \in X} D(\textbf{x})^2 } \)&lt;/li&gt;
  &lt;li&gt;Repeat the two previous steps \( k-1 \) times.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The benefits in terms of convergence speed and final error outweigh the computational overhead
for this initialization procedure; see the original paper &lt;a class=&quot;citation&quot; href=&quot;#arthur2006k&quot;&gt;(Arthur &amp;amp; Vassilvitskii, 2006)&lt;/a&gt; for details.
If you are looking for a thorough comparison of seeding techniques, I recommend this recent review
&lt;a class=&quot;citation&quot; href=&quot;#franti2019much&quot;&gt;(Fränti &amp;amp; Sieranoja, 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Keep in mind that a good initialization of the centroids should be as close as possible to the
optimal solution. &lt;strong&gt;Thus, finding a good initialization is not easier than solving the clustering problem itself.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Harmonic Means&lt;/h4&gt;

&lt;p&gt;The authors of &lt;em&gt;k-harmonic means&lt;/em&gt; &lt;a class=&quot;citation&quot; href=&quot;#zhang1999k&quot;&gt;(Zhang et al., 1999)&lt;/a&gt; claim their approach
is significantly less sensitive to initialization.
This algorithm does not optimize the SSE, but a different performance metric,
which relies on a soft assignment and takes the sum over all data points of the harmonic
average of the squared distance to all centroids.
\[ C_{best} = \underset{C}{\arg\min}  \sum_{\textbf{x} \in X} \frac{1}{ \sum_{i=1}^K \frac{1}{\lVert \textbf{x} - \textbf{c}_i \rVert^2} } \]&lt;/p&gt;

&lt;p&gt;Looking for the minimum of this expression with respect to centroids leads to a different update rule:&lt;/p&gt;

&lt;p&gt;\[
\begin{aligned}
 \forall 1\le i \le k, \,\, \textbf{c}^{t+1}_i &amp;amp;= \sum_{\textbf{x} \in X}  \frac{\alpha_{i,\textbf{x}}^t \textbf{x}}{\alpha_{i,\textbf{x}}^t} \\&lt;br /&gt;
 \text{with}\;\, \alpha_{i,\textbf{x}}^t &amp;amp;= \frac{1}{\vert\vert \textbf{x} - \textbf{c}_i^t \vert\vert^3 \left( \sum_{j=1}^K \frac{1}{\vert\vert \textbf{x} - \textbf{c}_j^t \vert \vert^2 } \right)^2 }
\end{aligned}
\]&lt;/p&gt;

&lt;p&gt;Check out the paper if you would like to implement &lt;em&gt;k-harmonic means&lt;/em&gt;. They propose an efficient
algorithm that reduces numerical instabilities.&lt;/p&gt;

&lt;h3 id=&quot;computational-time-complexity&quot;&gt;Computational Time Complexity&lt;/h3&gt;

&lt;p&gt;The assignment step time complexity is \( O(nkd) \)
where \( n \) is the number of samples, \( k \) is the number of clusters,
and  \( d \) is the input space dimension. &lt;strong&gt;This complexity is the consequence
of computing the pair-wise distance between all data points and all centroids&lt;/strong&gt;.
The update step has a time complexity of \( O(nd) \). The mean is computed along \( d \) dimensions for
\( k \) clusters, each containing an average of \( n/k \) data points.&lt;/p&gt;

&lt;p&gt;The overall &lt;strong&gt;time complexity at each step of the Lloyd algorithm is therefore \( O(nkd) \)&lt;/strong&gt;.
If all these values increase two-fold at once, then the algorithm will be eight times slower—not ideal.
In addition, the number of necessary iterations to reach convergence grows
sublinearly with \(k\), \(n\) and \(d\).&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Dimensionality Reduction&lt;/h4&gt;
&lt;p&gt;There are some ways to mitigate this scaling problem. The first one is to retain only the relevant dimensions
with a feature selection. The second is to &lt;strong&gt;project the data points into a smaller space&lt;/strong&gt; with
&lt;a href=&quot;https://en.wikipedia.org/wiki/Principal_component_analysis&quot;&gt;principal components analysis (PCA)&lt;/a&gt;,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Independent_component_analysis&quot;&gt;independent component analysis (ICA)&lt;/a&gt;,
or &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_discriminant_analysis&quot;&gt;linear discriminant analysis (LDA)&lt;/a&gt;.&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Batch Processing&lt;/h4&gt;
&lt;p&gt;A second approach to reducing the computational complexity is to use fewer
samples at each iteration. &lt;strong&gt;Rather than working
with all data points, the algorithm only manipulates a randomly selected subset.
This variant is called &lt;em&gt;mini-batch k-means&lt;/em&gt;&lt;/strong&gt;.
We usually want the batch size, noted \( b \), to be far greater than the number of clusters
and much lower than the number of samples (\( k \ll b \ll n \)).&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Triangular Inequality&lt;/h4&gt;
&lt;p&gt;We know the shortest path between two points is to follow a straight line rather than to stop
somewhere else in between. In mathematics this is known as the triangular inequality:
\[ \forall \textbf{x}, \textbf{y}, \textbf{z} \in \mathbb{R}^d ,\;\, 
\vert\vert \textbf{x} - \textbf{z} \vert\vert \leq \vert\vert \textbf{x} - \textbf{y} \vert\vert + \vert\vert \textbf{y} - \textbf{z} \vert\vert \]&lt;/p&gt;

&lt;p&gt;We can leverage this for our case:
given a data point \( \textbf{x} \) and two centroids \( \textbf{c}_1 \)
and \( \textbf{c}_2 \), if \( \vert\vert \textbf{x} - \textbf{c}_1 \vert\vert \leq \frac{1}{2} \vert\vert \textbf{c}_1 - \textbf{c}_2 \vert\vert \)
then \( \vert\vert \textbf{x} - \textbf{c}_1\vert\vert \leq \vert\vert \textbf{x} - \textbf{c}_2 \vert\vert \),
which means \( \textbf{x} \) belongs to the cluster represented by \(\textbf{c}_1\).
Consequently, we do not not need to compute \( \vert\vert \textbf{x} - \textbf{c}_2 \vert\vert \).&lt;/p&gt;

&lt;p&gt;Over the course of the training, the &lt;em&gt;Elkan algorithm&lt;/em&gt; &lt;a class=&quot;citation&quot; href=&quot;#elkan2003using&quot;&gt;(Elkan, 2003)&lt;/a&gt;
keeps track of the upper bounds for the distances between all data points and 
the centroids (noted \( u_{\textbf{x},\textbf{c}} \) ). Suppose
\( u_{\textbf{x},\textbf{c}_1}  \geq \vert\vert \textbf{x} - \textbf{c}_1 \vert\vert \),
then we can spare the computations of \( \vert\vert \textbf{x} - \textbf{c}_2 \vert\vert \)
if \( u_{\textbf{x},\textbf{c}_1}  &amp;gt; \vert\vert \textbf{c}_1 -  \textbf{c}_2 \vert\vert \).
The upper bounds get updated at each iteration as the centroids keep on moving.&lt;/p&gt;

&lt;h3 id=&quot;sensitivity-to-outliers&quot;&gt;Sensitivity to Outliers&lt;/h3&gt;

&lt;p&gt;The centroid locations are defined as the mean positions of the data points within each cluster.
However, &lt;strong&gt;the mean is an estimator sensitive to outliers&lt;/strong&gt;. Outliers are data points that are 
significantly different from the other ones (out of distribution samples).
Fig.3 illustrates this issue, where two data points out of distribution have a disproportionate impact on
the final result. &lt;strong&gt;Not only are some points not assigned to the right cluster, but the decision
boundary is ultimately different&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/outliers_off.png&quot; alt=&quot;k-means nwithout outliers&quot; style=&quot;max-width:300px;display:inline-block;width:48%;&quot; /&gt;
  &lt;img src=&quot;/assets/img/outliers_on.png&quot; alt=&quot;kmeans with outliers&quot; style=&quot;max-width:300px;display:inline-block;width:48%;&quot; /&gt;
  &lt;figcaption&gt;Fig. 4 — Without outliers (left) and with outliers (right).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;If possible, a solution could be to &lt;strong&gt;preprocess the data by filtering out the outliers&lt;/strong&gt;.
A different remedy could be to &lt;strong&gt;weight each data point&lt;/strong&gt;. During the update step,
weighted-mean is therefore used. &lt;em&gt;Weighted k-means&lt;/em&gt; can reduce the impact of the outliers
and avoid the need for a hard decision in the preprocessing.
Finding a good weighting strategy is not easy and might take a few trials.&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Different Aggregators&lt;/h4&gt;
&lt;p&gt;There are two more variants of &lt;em&gt;k-means&lt;/em&gt; designed to reduce the influence of outliers.
For the first one, &lt;strong&gt;the centroids are no longer defined as the mean locations but as the median positions.
The algorithm is rightfully called &lt;em&gt;k-medians&lt;/em&gt;&lt;/strong&gt;. &lt;em&gt;K-means&lt;/em&gt; minimize the within cluster-variance (L2-norm)
while &lt;em&gt;k-medians&lt;/em&gt; minimize the absolute deviation (L1-norm). For k-medians, the update rule becomes:&lt;/p&gt;

&lt;p&gt;\[ \forall 1\le i \le k, \,\, c^{t+1}_i = \text{median}( S^t_i ) \]&lt;/p&gt;

&lt;p&gt;The second adaptation enforces some restrictions to centroids. Rather than taking any possible locations, 
the &lt;strong&gt;centroids are restricted to the set of data points. This algorithm is called &lt;em&gt;k-medoids&lt;/em&gt;&lt;/strong&gt;
(or Partitioning Around Medoids). A medoid is the most central representant in a cluster
which minimizes the sum of distances to other data points. This distance metric makes &lt;em&gt;k-medoids&lt;/em&gt;
more robust to outliers.
For &lt;em&gt;k-medoids&lt;/em&gt;, the optimal solution is given by:&lt;/p&gt;

&lt;p&gt;\[ C_{best} = \underset{X}{\arg\min}  \sum_{i=1}^{k} \sum_{\textbf{x} \in S_i} \lVert \textbf{x} - \textbf{c}_i \rVert \]&lt;/p&gt;

&lt;p&gt;Finding the right medoids requires a different algorithm (out of scope for
this post) and has a higher computational complexity of \( O(k(n-k)^2) \) at each iteration step.
See PAM, CLARA, and CLARANS algorithms &lt;a class=&quot;citation&quot; href=&quot;#schubert2019faster&quot;&gt;(Schubert &amp;amp; Rousseeuw, 2019)&lt;/a&gt; if you are interested.&lt;/p&gt;

&lt;h3 id=&quot;shape-and-extent-of-clusters&quot;&gt;Shape and Extent of Clusters&lt;/h3&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Convexity of Partitions&lt;/h4&gt;

&lt;p&gt;K-means, and all its variants, minimize distortion and &lt;strong&gt;optimize the clusters for compactness.
The implicit assumption is that clusters are roughly spherical&lt;/strong&gt;
(&lt;a href=&quot;https://en.wikipedia.org/wiki/Isotropy&quot;&gt;isotropic&lt;/a&gt;, uniform in all directions).
Depending on the distribution of data points, some clusters might not be exactly spherical, but they
will &lt;strong&gt;at least form convex partitions&lt;/strong&gt;. Convex means that for any two points in the same cluster,
the whole segment from one point to the other is fully contained inside the Voronoi cell.&lt;/p&gt;

&lt;p&gt;Some good examples of failing cases are concentric circles, half-moons, and the smiley,
as illustrated in the figure below. There is no way for &lt;em&gt;k-means&lt;/em&gt; to isolate
the inner ring from the external ring, as the outermost partition will not be convex.
The same problem applies to the 4 components of the smiley. For the two half-moons, the geometrical
properties of each cluster cannot be captured.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/rings.png&quot; alt=&quot;Rings dataset&quot; style=&quot;max-width:300px;display:inline-block;width:32.5%;&quot; /&gt;
  &lt;img src=&quot;/assets/img/halfmoons.png&quot; alt=&quot;Half moons datasets&quot; style=&quot;max-width:300px;display:inline-block;width:32.5%;&quot; /&gt;
  &lt;img src=&quot;/assets/img/smiley.png&quot; alt=&quot;Smiley datasets&quot; style=&quot;max-width:300px;display:inline-block;width:32.5%;&quot; /&gt;
  &lt;figcaption&gt;Fig. 5 — Partitions for non-convex and geometric clusters. Concentric&amp;nbsp;rings&amp;nbsp;(left, k=8), half&amp;nbsp;moons&amp;nbsp;(center,&amp;nbsp;k=4) and smiley&amp;nbsp;(right,&amp;nbsp;k=12)&amp;nbsp;datasets&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;One partial solution is to &lt;strong&gt;overestimate the number of clusters and merge the partitions later on&lt;/strong&gt;.
However, that might not be easy for high-dimensional data, and it will never really compensate if the data
distribution violates the initial assumption of spherical/convex clusters.&lt;/p&gt;

&lt;p&gt;One might want to use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method#Mathematics:_the_kernel_trick&quot;&gt;kernel trick&lt;/a&gt;
to operate in a higher dimensional space. The hope is that in the projected space the data will comply with the spherical
distribution hypothesis. Finding the right kernel function could be cumbersome.&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Similar Expansions&lt;/h4&gt;
&lt;p&gt;A further limitation is the relative size of clusters. By placing the decision boundaries halfway between 
centroids, &lt;strong&gt;the underlying assumption is that clusters are evenly sized along that direction&lt;/strong&gt;.
The size is defined as the spatial extent (area, volume, or &lt;a href=&quot;https://en.wikipedia.org/wiki/Lebesgue_measure&quot;&gt;Lebesgue measure&lt;/a&gt;)
—not the number of data points assigned inside the cluster.&lt;/p&gt;

&lt;p&gt;Once again, some datasets with complex geometrical shapes
might not match this assumption. The perfect example is the Mickey Mouse dataset.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/mickey.png&quot; alt=&quot;mickey dataset&quot; style=&quot;max-width:300px;display:inline-block;width:49%;&quot; /&gt;
  &lt;img src=&quot;/assets/img/tshape.png&quot; alt=&quot;T shape datasets&quot; style=&quot;max-width:300px;display:inline-block;width:49%;&quot; /&gt;
  &lt;figcaption&gt;Fig. 6 — K-means partitions with anisotropic clusters and different&amp;nbsp;variances.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Finally, the &lt;em&gt;k-means&lt;/em&gt; could fail if data arises from blobs with similar sizes, but some generate far
fewer observations. This is somewhat related to the initialization problem: selecting a centroid from
the underrepresented class is less likely.&lt;/p&gt;

&lt;p&gt;To sum up, k-means clustering assumes the clusters have convex shapes (e.g. a circle, a sphere),
all partitions should have similar sizes, and the clusters are balanced.&lt;/p&gt;

&lt;h4 class=&quot;no_toc&quot;&gt;Capturing Variances&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;K-means&lt;/em&gt; and its variants only learn the central location of clusters—nothing more.
&lt;strong&gt;It would be relevant to also capture the spatial extent of each cluster&lt;/strong&gt;. The
&lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Mixture_model&quot;&gt;Gaussian Mixture Model&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;GMM&lt;/em&gt;)
was designed to capture the mean location and standard deviation of the data.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GMM&lt;/em&gt; computes the probability for all data points to belong to a cluster, for all clusters. 
This is called a &lt;em&gt;soft assignment&lt;/em&gt;, in opposition to the hard assignment to one and
only one cluster used by &lt;em&gt;k-means&lt;/em&gt;. &lt;em&gt;GMM&lt;/em&gt; is a powerful tool. There is a lot to say about it,
but that will be a story for another time.&lt;/p&gt;

&lt;h3 id=&quot;optimal-number-of-clusters&quot;&gt;Optimal Number of Clusters&lt;/h3&gt;

&lt;p&gt;Last but not least, finding the optimal number of clusters is necessary to achieve good performance.
Priors or domain knowledge can be very handy for this task.
To this day, more than 30 methods have been published on this topic.
I will try to cover the most common methods.&lt;/p&gt;

&lt;h4 id=&quot;the-elbow-method&quot;&gt;The Elbow Method&lt;/h4&gt;

&lt;p&gt;First of all, we need to define a metric which tells how compact the clusters are.
A pertinent metric for this is the &lt;strong&gt;within-cluster sum squared error&lt;/strong&gt; (\(SSE\) or \(WSS\)).
It is defined as the sum of squared distance between each point and its closest centroid.&lt;/p&gt;

&lt;p&gt;\[ SSE(k) = \sum_{i=1}^{k} \sum_{\textbf{x} \in S_i} \vert\vert \textbf{x} - \textbf{c}_i \vert\vert^2 \]&lt;/p&gt;

&lt;p&gt;This function is strictly decreasing when applied on converged models. At first,
when we add clusters it gets easier to model the data. But after a certain point,
increasing the number of clusters brings little additional benefits,
as it only splits clusters into sub-groups or starts modelling the noise.
&lt;strong&gt;The &lt;em&gt;Elbow method&lt;/em&gt; &lt;a class=&quot;citation&quot; href=&quot;#thorndike1953belongs&quot;&gt;(Thorndike, 1953)&lt;/a&gt; is a heuristic to
find this point of diminishing return&lt;/strong&gt;.
The analysis is performed by plotting the evolution of the explained variance as the number 
of clusters grows. &lt;strong&gt;The optimal number of clusters is located at the bend,
the elbow of the curve.&lt;/strong&gt;&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/elbow.png&quot; alt=&quot;Explained variance&quot; style=&quot;max-width:680px;display:inline-block;width:103%;&quot; /&gt;
  &lt;figcaption&gt;Fig.7 — Explained variance&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;\( SSE \) is often applied once the model has converged.
However, it can also be used as a stopping criteria for the algorithm.
If \( SSE \) is computed at the end of each iteration, a heuristic
could be to stop the training when the \( SSE \) decreases less than a
certain threshold compared to the previous step.&lt;/p&gt;

&lt;h4 id=&quot;gap-statistic&quot;&gt;Gap Statistic&lt;/h4&gt;

&lt;p&gt;The &lt;em&gt;Elbow Method&lt;/em&gt; is far from ideal. The elbow is not formally defined,
and a visual inspection is necessary to localise it.
Consequently, the estimation of the optimal number of clusters can be subjective.
Not all SSE curves will have a sharp elbow like in the example above!&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;gap statistic analysis&lt;/em&gt; &lt;a class=&quot;citation&quot; href=&quot;#tibshirani2001estimating&quot;&gt;(Tibshirani et al., 2001)&lt;/a&gt; addresses this problem.
The idea behind it is to &lt;strong&gt;compare the SSE measured on the data with the SSE computed on a dataset
without obvious clustering&lt;/strong&gt; (data with a null reference distribution). The SSE on the data should be 
further away from the reference value for the optimal number of clusters.&lt;/p&gt;

&lt;p&gt;The equation looks like this :&lt;/p&gt;

&lt;p&gt;\[ G(k) =  \log SSE(X^*, k) - \log SSE(X, k) \]&lt;/p&gt;

&lt;p&gt;We denote by \( X^* \) a dataset with data points &lt;strong&gt;uniformly distributed&lt;/strong&gt;
in the interval defined by the minimum and maximum values of \( X\) along each \( d \) component.&lt;/p&gt;

&lt;p&gt;The expected SSE on the null distribution, the first term of the equation,
is &lt;strong&gt;estimated with bootstrapping&lt;/strong&gt;. This means we sample \( B \) different datasets
\(X_b^* \; \forall 1 \leq b \leq B\) and compute the mean logarithm of SSE.
The estimation gets more accurate with higher values of B.
However, keep in mind that \( G_B(k) \) is only computed once &lt;em&gt;k-means&lt;/em&gt; has converged \( B+1 \) times.
The expression of the gap function becomes:&lt;/p&gt;

&lt;p&gt;\[ G_B(k) = \frac{1}{B} \sum_{b=1}^{B} \log SSE(X_b^*, k) - \log SSE(X, k) \]&lt;/p&gt;

&lt;p&gt;The optimal number of clusters is the smallest k such that \( G(k) \geq G(k+1) - s_{k+1} \) where
\( s_k = \sqrt{1 + 1/B}\;\text{std}_B(\log SSE(X_b^*, k)) \) accounts for the simulation error.&lt;/p&gt;

&lt;p&gt;Our toy example is simple enough so identifying the k which meets this condition is straightforward (k=4).&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/img/gap.png&quot; alt=&quot;kmeans gap statistic analysis&quot; style=&quot;max-width:660px;display:inline-block;width:100%;&quot; /&gt;
  &lt;img src=&quot;/assets/img/gap-cond.png&quot; alt=&quot;kmeans gap condition&quot; style=&quot;max-width:680px;display:inline-block;width:103%;&quot; /&gt;
  &lt;figcaption&gt;Fig.8 — Gap statistic analysis&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;silhouette-analysis&quot;&gt;Silhouette Analysis&lt;/h4&gt;

&lt;p&gt;Silhouette coefficient &lt;a class=&quot;citation&quot; href=&quot;#rousseeuw1987silhouettes&quot;&gt;(Rousseeuw, 1987)&lt;/a&gt; is a
&lt;strong&gt;quality measurement for partitioning&lt;/strong&gt;. The silhouette score measures how close
a data point is to its counterparts in the same cluster compared to other elements
in other clusters. &lt;strong&gt;The score captures the cohesion (within-cluster distances)
and the separation (inter-cluster distances)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The average dissimilarity of a data point \( \textbf{x} \) with elements in a cluster is defined as:&lt;/p&gt;

&lt;p&gt;\[ d(\textbf{x}, S_i) = \frac{1}{n_i - 1} \sum_{\textbf{x}_i \in S_i} \vert\vert \textbf{x}_i - \textbf{x} \vert\vert \]&lt;/p&gt;

&lt;p&gt;The cohesion score (the lower, the better) of \( \textbf{x} \), which belongs to
partition \( S_{\textbf{x}} \), is the intra-cluster
distance: \( a(\textbf{x}) = d(\textbf{x}, S_{\textbf{x}}) \).
The partition that does not contain \( \textbf{x} \) and minimize \( d(\textbf{x}, S_i) \)
is called the &lt;strong&gt;neighboring cluster&lt;/strong&gt;. The separation score (the higher, the better) is
defined as the average dissimilarity of \( \textbf{x} \) with the neighbouring
cluster: \( b(\textbf{x}) = \min_{i, \textbf{x}\notin S_i} d(\textbf{x}, S_i) \).
The silhouette coefficient combines these two scores:&lt;/p&gt;

&lt;p&gt;\[ s(\textbf{x}) = \frac{b(\textbf{x}) - a(\textbf{x})}{\max\{a(\textbf{x}), b(\textbf{x})\}} \]&lt;/p&gt;

&lt;p&gt;If the cluster only contains 1 data point, the silhouette score is set to 0.
The score varies from -1 to 1. A score close to 1 represents data points well assigned to clusters.
If the score is positive, the data point is on average closer to elements
in the cluster it belongs to rather than elements in the neighbouring cluster.
On the contrary, if it is negative, the data point should belong to the neighbouring cluster.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The mean silhouette score over all data points is a measure of the partitioning quality&lt;/strong&gt;.
This quality score can be computed for several values of \(k\).
&lt;strong&gt;The best number of clusters yields the highest average silhouette coefficient&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;It is possible to gain much more insight about the quality of partitioning
by plotting the sorted silhouette coefficients per cluster for different numbers of clusters.
The silhouette analysis looks like this:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/silhouette234.png&quot; alt=&quot;Silhouette k=2,3,4&quot; style=&quot;max-width:680px;display:inline-block;width:103%;&quot; /&gt;
  &lt;img src=&quot;/assets/img/silhouette567.png&quot; alt=&quot;Silhouette k=5,6,7&quot; style=&quot;max-width:680px;display:inline-block;width:103%;&quot; /&gt;
  &lt;figcaption&gt;Fig.9 — Silhouette diagram analysis&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;For the &lt;strong&gt;optimal number of clusters, the silhouette plots should&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;have the same thickness&lt;/strong&gt; (same number of observations)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;have the same profile&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;intersect with the average silhouette score&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In Fig.8, we can rule out \(k=3,5,6,7\). The graphical analysis is ambivalent between \(k=2\)
and \(k=4\). However, the latter has a higher average value. The conclusion of the analysis
is that best results are obtained with \(k=4\).&lt;/p&gt;

&lt;p&gt;The Elbow method has a linear time complexity of \(O(nd)\). The silhouette computes all pairwise distances,
so time complexity jumps to \(O(n^2d)\). It’s not cheap, and in fact it’s worse than the Lloyd algorithm
itself on most datasets.&lt;/p&gt;

&lt;!---
&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;&gt;&lt;/script&gt;
&lt;div id=&quot;silhouette&quot; style=&quot;width:400px;height:500px;&quot;&gt;&lt;/div&gt;
&lt;script&gt;
let n_i = centroids.map((c, idx) =&gt; data.filter(d =&gt; d.cluster == idx).length)
for (let i=0; i&lt;data.length; i++) {
  data[i].d = centroids.map(c =&gt; 0);
  for (let j=0; j&lt;data.length; j++) {
     data[i].d[data[j].cluster] += l2dist(data[i], data[j]) / (n_i[data[j].cluster] - 1);
  }
  const a = data[i].d[data[i].cluster];
  data[i].d.splice(data[i].cluster, 1);
  const b = Math.min(...data[i].d);
  data[i].s = (b - a) / Math.max(b, a);
}

const cumulativeSum = (sum =&gt; value =&gt; sum += value)(0);
let n_i_cum = n_i.map(cumulativeSum);
n_i_cum.unshift(0);

const average = arr =&gt; arr.reduce((sume, el) =&gt; sume + el, 0) / arr.length;
let avg_sil = average(data.map(d =&gt; d.s))

let traces = centroids
  .map((c, idx) =&gt; data.filter(d =&gt; d.cluster==idx).map(d =&gt; d.s))
  .map((sil, idx) =&gt; {return {
    y: d3.range(n_i_cum[idx] + 10*idx, n_i_cum[idx] + 10*idx + sil.length),
    x: sil.sort(),
    mode: 'line',
    fill: 'tozerox',
    xaxis: 'x',
    yaxis: 'y',
  }})
traces.push({y: [0, n_i_cum[k] + 10*k], x: [avg_sil, avg_sil], mode: 'lines', line: {color: &quot;grey&quot;}});
let layout = {
  showlegend: false,
  annotations: [{
    x: avg_sil,
    y: n_i_cum[k] + 10*k,
    xref: 'x',
    yref: 'y',
    text: 'Avg silhouette value',
    font: {family: 'Times New Roman', size: 16},
    showarrow: true,
    arrowhead: 7,
    ax: 0,
    ay: -10,
  }],
  title: {
    text:'Silhouette Histograms',
    font: {family: 'Times New Roman', size: 16},
  },
  xaxis: {
    title: {
      text: 'Silhouette value (k=' + k + ')',
      font: {family: 'Times New Roman', size: 16},
      standoff: 0,
    },
    range: [-0.1, 0.81]
  },
  yaxis: {
    title: {
      text: 'Histogram per clusters',
      font: {family: 'Times New Roman', size: 16},
      standoff: -100,
    },
    ticks: '',
    showticklabels: false,
    showgrid: false,
  },
};
Plotly.newPlot(&quot;silhouette&quot;, traces, layout);


function sse(data, centroids) {
 return data.map(d =&gt; (d.x - centroids[d.cluster].x)**2 + (d.y - centroids[d.cluster].y)**2).reduce((a, b) =&gt; a+b)
}

&lt;/script&gt;
--&gt;

&lt;h4 id=&quot;measures-of-information&quot;&gt;Measures of Information&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;A good estimator of the model performance should take into account the quality of the model
but should also penalise for the complexity of the model. Bayesian Information Criterion&lt;/strong&gt; (&lt;em&gt;BIC&lt;/em&gt;)
&lt;a class=&quot;citation&quot; href=&quot;#schwarz1978estimating&quot;&gt;(Schwarz &amp;amp; others, 1978)&lt;/a&gt; and &lt;strong&gt;Akaike Information Criterion&lt;/strong&gt; (&lt;em&gt;AIC&lt;/em&gt;)
&lt;a class=&quot;citation&quot; href=&quot;#akaike1974new&quot;&gt;(Akaike, 1974)&lt;/a&gt; measure the statistical quality of a model and respect this
parsimony principle (more parameters should not be added without necessity). For both
metrics, the lower the better.&lt;/p&gt;

&lt;p&gt;For k-means, the simplest expressions for \( BIC \) and \( AIC \) are defined as:
\begin{aligned}
 BIC &amp;amp;= \frac{SSE}{\hat\sigma^2} + kd\log(n) \\ 
 AIC &amp;amp;= \frac{SSE}{\hat\sigma^2} + 2kd 
\end{aligned}&lt;/p&gt;

&lt;p&gt;\( \hat\sigma^2 \) is the average intra-cluster variance defined on a model
with a very high number of clusters &lt;a class=&quot;citation&quot; href=&quot;#friedman2001elements&quot;&gt;(Friedman et al., 2001, sec. 7.7)&lt;/a&gt;:
\( \hat\sigma^2 = \frac{SSE(k’)}{k’},\; k’&amp;gt;k \). It is worth computing \( \hat\sigma^2 \)
for several values of \( k’ \). Small \( k’ \) penalizes models with high number of clusters
more heavily&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/bic-aic.png&quot; alt=&quot;kmeans BIC and AIC measure&quot; style=&quot;max-width:680px;display:inline-block;width:103%;&quot; /&gt;
  &lt;figcaption&gt;Fig.10 — BIC and AIC&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;From the above figure, we can see that curves for \(k’=16\) and \(k’=20\)
are overlapping, for both \( BIC \) and \(AIC\) since
the average intra-cluster variances are nearly equal. In both cases, and for both
metrics, the optimal number of clusters is 4.&lt;/p&gt;

&lt;p&gt;The story and the conclusion is a bit different for \( k’=12 \).
The minimum for \( BIC \) is reached for \( k = 2 \) but the minimum 
for \( AIC \) is obtained with \( k = 4 \). &lt;strong&gt;This illustrates that small
\(k’\) leads to models with fewer clusters. It also shows that BIC
yields a higher penalty than \(AIC\)&lt;/strong&gt;.&lt;/p&gt;

&lt;details&gt;
  &lt;summary style=&quot;background:#eee&quot;&gt;This is not the whole story. Click to expand if you like equations!&lt;/summary&gt;
  &lt;div style=&quot;background:#eee;padding:5px&quot;&gt;

&lt;p&gt;
\(BIC\) and \(AIC\) are originally defined as: 
&lt;br /&gt;
\( BIC = p\log(n) - 2 \log\left(L (M; X) \right) \) and \( AIC = 2p - 2 \log\left(L (M; X) \right) \)
&lt;br /&gt;where \( M \) is the model, \( p \) is the number of free-parameters of \( M \),
and \( L (M; X) \) is the model likelihood.
&lt;/p&gt;

&lt;p&gt;
With k-means, we can heavily rely on the assumption that data arises
from identical isotropic blobs. Observed data points can be decomposed
as \( \textbf{x} = \mu + e, \; \forall \textbf{x} \in X \) where the \( \mu \)
is one of the centroids, \(\mu \in C \);
and the error follows a multivariate Gaussians, \( e \sim \mathcal{N}(0,\,\sigma^{2}I_d)\).
&lt;/p&gt;

&lt;p&gt;
Given a partition of the space, the probability to observe a data point \( \textbf{x} \) is therefore defined by:

\[ P(\textbf{x} \vert S) = \frac{n_i}{n} 
\frac{1}{\sqrt{2 \pi \sigma^2}^{d}} \exp \left( -\frac{\vert \vert \textbf{x} - \textbf{c}_i \vert \vert_2^2}{2\sigma^2} \right) \]
&lt;/p&gt;


&lt;p&gt;
This can be injected into the log-likelihood:

\[ \begin{aligned}
\log &amp;amp; L(S; X)  = \log \prod_{\textbf{x} \in X} P(\textbf{x} \vert S) = \sum_{i=1}^{k} \sum_{\textbf{x} \in S_i} \log P(\textbf{x} \vert S)
               \\ &amp;amp;= \sum_{i=1}^{k} \left[ n_i \log\left(\frac{n_i}{n}\right) -  \frac{\sum_{\textbf{x} \in S_i} \vert \vert \textbf{x} - \textbf{c}_i \vert \vert_2^2}{2\sigma^2}\right] - \frac{nd}{2}\log(2\pi\sigma^2)
\end{aligned} \]

If we consider that all &lt;b&gt;clusters are evenly balanced&lt;/b&gt;, and if we assume &lt;b&gt;\( \sigma^2 \)
to be fixed&lt;/b&gt;, then \( BIC \) and \(AIC\) are equal to the previous equation
with an additive constant. Even if \( \sigma^2 \) is considered fixed, it is unknown. Its value is estimated in
a low-bias regime.
&lt;/p&gt;

&lt;p&gt;
Now, &lt;b&gt;let's assume \( \sigma^2 \) can be estimated from the data.&lt;/b&gt;
The unbiased estimator of the variance for each cluster gives:

\[ \forall 1\le i \le k, \; \hat\sigma_i^2 = \frac{1}{d(n_i - 1)} \sum_{\textbf{x} \in S_i} \vert\vert \textbf{x} - \textbf{c}_i \vert\vert^2 \]

Combined with the definition of SSE, we end up with:

\[ SSE = \sum_{i=1}^{k} \sum_{\textbf{x} \in S_i} \vert\vert \textbf{x} - \textbf{c}_i \vert\vert^2 = \sum_{i=1}^k d(n_i - 1) \hat \sigma_i^2 \]
&lt;/p&gt;

&lt;p&gt;
With the underlying assumption that all clusters have the same extent, we have \( \hat\sigma^2 = \hat \sigma_i^2 \).
In conclusion, the unbiased estimation of the variance is: 

\[ \hat\sigma^2 = \frac{1}{d(n-k)}  \sum_{i=1}^{k} \sum_{\textbf{x} \in S_i} \vert\vert \textbf{x} - \textbf{c}_i \vert\vert^2 = \frac{SSE}{d(n-k)} \]
&lt;/p&gt;

Going back to the log-likelihood formula, it can be simplified into:

\[ \begin{aligned}
\log &amp;amp;  L(S; X) =  \sum_{i=1}^{k} \left[ n_i \log\left(\frac{n_i}{n}\right) \right] - \frac{d(n-k)}{2} - \frac{nd}{2}\log(2\pi\sigma^2)
\end{aligned} \]

In the end, knowing that there are \( p=k\times d \) free parameters for k-means, the \( BIC \) and \( AIC \) expressions become:

\[ \begin{aligned}
 BIC &amp;amp; =(2n + dk)\log(n) + d(n-k) + nd\log(2\pi\sigma^2) - 2 \sum_{i=1}^{k} n_i \log\left(n_i\right)
\\ AIC &amp;amp; = 2n\log(n) + d(n+k) + nd\log(2\pi\sigma^2) - 2 \sum_{i=1}^{k} n_i \log\left(n_i\right)
\\ \text{with}&amp;amp;\; \sigma^2 = \frac{SSE}{d(n-k)}
\end{aligned} \]

There is still one limitation with these equations: they consider
the assignment as the true label for classification rather than 
taking into account the uncertainty in this assignment.
I recommend this article &lt;a class=&quot;citation&quot; href=&quot;#hofmeyr2020degrees&quot;&gt;(Hofmeyr, 2020)&lt;/a&gt; which
shows that the number of free parameters is underestimated.

&lt;/div&gt;&lt;/details&gt;

&lt;!--#### Clustergram?--&gt;
&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#schonlau2002clustergram&quot;&gt;(Schonlau, 2002)&lt;/a&gt;--&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;K-means’&lt;/em&gt; high notoriety is certainly due to its simplicity and ease of implementation.
However, it has quite a few limitations: the dependence on the initial centroids,
the sensitivity to outliers, the spherical/convex clusters, and the troubles of clustering
groups of different density and spatial extent.&lt;/p&gt;

&lt;p&gt;It is also necessary to standardize the data to have zero mean and unit standard deviation.
Otherwise, the algorithm might struggle or give too much importance to certain features.&lt;/p&gt;

&lt;h2 id=&quot;interview-questions&quot;&gt;Interview Questions&lt;/h2&gt;

&lt;p&gt;Try to answer the following questions to assess your understanding of &lt;em&gt;k-means&lt;/em&gt; and its variants.
These questions are often asked during interviews for data science positions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What is clustering?&lt;/li&gt;
  &lt;li&gt;Is clustering a supervised or an unsupervised technique?&lt;/li&gt;
  &lt;li&gt;Can you describe the K-means algorithm?&lt;/li&gt;
  &lt;li&gt;What is its complexity? How would you reduce the number of computations?&lt;/li&gt;
  &lt;li&gt;What are some termination criteria?&lt;/li&gt;
  &lt;li&gt;What is the difference between hard and soft assignments?&lt;/li&gt;
  &lt;li&gt;What are some weaknesses of k-means?&lt;/li&gt;
  &lt;li&gt;The algorithm has some assumptions about the data distribution. What are they?&lt;/li&gt;
  &lt;li&gt;How do you find the optimal number of clusters?&lt;/li&gt;
  &lt;li&gt;How come two different executions of the algorithm produce different results? How does one address this problem?&lt;/li&gt;
  &lt;li&gt;What kind of preprocessing would you apply to the data before running the algorithm?&lt;/li&gt;
  &lt;li&gt;Is the algorithm sensitive to outliers? If yes, how could you mitigate the problem?&lt;/li&gt;
  &lt;li&gt;What are the applications of k-means clustering?&lt;/li&gt;
&lt;/ul&gt;
</description>
        
          <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax = {
  loader: {load: ['[tex]/color']},
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)'], ['\\[', '\\]']],
    packages: {'[+]': ['color']}
  },
  svg: {
    fontCache: 'glo\(( bal',
    linebreak: 
      automatic: true
  }
};
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://d3js.org/d3.v6.min.js&quot;&gt;&lt;/script&gt;

&lt;style&gt;
.MathJax {
  overflow-x:auto;
}
svg.animation {
  box-shadow: 0 10px 16px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19) !important;
}
figure {
  text-align: center;
  margin: 0.5rem auto 2rem auto !important;
}
&lt;/style&gt;

</description>
        
        <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
        <link>https://antoinebrl.github.io//blog/kmeans/</link>
        <guid isPermaLink="true">https://antoinebrl.github.io//blog/kmeans/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>Convolution Interactive Sandbox</title>
        <description>&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;&quot; /&gt;
  &lt;script src=&quot;https://d3js.org/d3.v4.min.js&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
  &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
  MathJax = {
    loader: {load: ['[tex]/color']},
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)'], ['\\[', '\\]']],
      packages: {'[+]': ['color']}
    },
    svg: {
      fontCache: 'global'
    }
  };

  &lt;/script&gt;
  &lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/input/tex/extensions/colorV2.js&quot; charset=&quot;UTF-8&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/input/tex/extensions/color.js&quot; charset=&quot;UTF-8&quot;&gt;&lt;/script&gt;
  &lt;style&gt;
    body {
      font-family: monospace;
      font-size: 12px;
      color: #818181;
      background-color: #f4f1de;
      /* background-color: #eeeeee; */
      margin: auto;
      height: 100%;
      text-align: center;
      /* width: 30%; */
      overscroll-behavior-y: none;
    }

    h1, h2{
        font-weight: 1.2;
        color: #505050;
    }
    h2 {
      text-align: left;
      margin-bottom: 0.5em;
    }
    hr {
      color: white;
      border-width: 1px;
    }


    .btn-square {
      height: 1.5em !important;
      width: 1.5em  !important;
    }
    input[type=radio]{
      vertical-align: text-bottom;
      line-height: 0.4em;
    }
    input[type=range]{
      vertical-align: middle;
      line-height: 1.6em;
      width: 120;
    }
    input[type=number]{
      width: 56px;
    }

    #math {
      width: 100%;
      height: 90px;
      font-size: 1.25em;
    }
    .menu {
      /* margin-left: 5px; */
      /* margin-right: 5px; */
      padding-top: 12px;
      padding-bottom: 12px;
      border-bottom: 1px solid lightgray;
    }
    .menu h1, .menu .option {
      display: inline;
    }
    .option {
        position:fixed;
        left: 8px;
        top: 2px;
    }

    .rotate270 {
        writing-mode: vertical-rl;
        transform: rotate(180deg);
        text-align: right;
    }
    .menu .btn {
      /* height:105px; */
      z-index: 2; /* Stay on top */
    }

    .btn{
        display: inline-block;
        padding: 6px 5px;
        margin-bottom: 0;
        font-size: 14px;
        text-align: center;
        /* font-weight: 400; */
        line-height: 1.42857143;
        white-space: nowrap;
        vertical-align: middle;
        -ms-touch-action: manipulation;
        touch-action: manipulation;
        cursor: pointer;
        -webkit-user-select: none;
        -moz-user-select: none;
        -ms-user-select: none;
        user-select: none;
        background-image: none;
        border: 1px solid transparent;
        border-radius: 4px;
        text-decoration: none;
        margin-top: 4px;
        margin-bottom : 4px;
        height: 2em;

        color: #4e5462;
        background-color: #fff;
        border-color: #ccc;
    }
    .btn:hover {
      background-color: #eee;
      border-color: #aaa;
    }

    #result-btn {
        margin-top: 34px !important;
        cursor: default !important;
        border-bottom: 0px !important;
        border-top: 0px !important;
        border-right: 0px !important;
    }
    #result-btn:hover {
        border-bottom: 0px !important;
        border-top: 0px !important;
        border-right: 0px !important;
        background-color: #fff !important;
        border-color: #ccc !important ;
    }

    /* The side navigation menu */
   .sidenav {
       height: auto; /* 100% Full-height */
       width: 0; /* 0 width - change this with JavaScript */
       position: fixed; /* Stay in place */
       z-index: 10; /* Stay on top */
       background-color: #eee; /* Black*/
       overflow-x: hidden; /* Disable horizontal scroll */
       transition: 0.5s; /* 0.5 second transition effect to slide in the sidenav */
       margin-left: 8px;
       margin-top: -6px;
       box-shadow: 0px 0px 0px 1px lightgray inset;
       /* border: 1px solid lightgray; */
       box-sizing: border-box;
   }

   /* The navigation menu links */
   .sidenav a {
       color: #818181;
       display: block;
       transition: 0.3s;
   }

   /* When you mouse over the navigation links, change their color */
   .sidenav a:hover {
     color: #111;
   }

   /* Position and style the close button (top right corner) */
   .sidenav .closebtn {
       position: absolute;
       top: 8px;
       right: 8px;
       font-size: 2em;
       margin-left: 20px;
   }

   /* Style page content - use this if you want to push the page content to the right when you open the side navigation */
   #main {
     transition: margin-left .5s;
     padding: 20px;
   }

   /* On smaller screens, where height is less than 450px, change the style of the sidenav (less padding and a smaller font size) */
   @media screen and (max-height: 450px) {
     .sidenav {padding-top: 15px;}
     .sidenav a {font-size: 18px;}
   }

   .nav-wrapper {
     margin: 10px;
     width: 280px;
   }

   .grabbing {
     cursor: move;
   }

   #player .btn {
     width: 80px;
     height: 20px;
   }


  &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;div class=&quot;menu&quot;&gt;
    &lt;h1&gt;Convolution Sandbox&lt;/h1&gt;
    &lt;div class=&quot;option btn&quot; onclick=&quot;openNav('menu')&quot;&gt;options&lt;/div&gt;
    &lt;div id=&quot;menu&quot; class=&quot;sidenav&quot;&gt;
      &lt;div class=&quot;nav-wrapper&quot;&gt;
        &lt;a href=&quot;javascript:void(0)&quot; class=&quot;closebtn&quot; onclick=&quot;closeNav('menu')&quot;&gt;&amp;times;&lt;/a&gt;
        &lt;h2&gt;General:&lt;/h2&gt;
          &lt;p&gt;sphere radius:&amp;nbsp;&lt;input id=&quot;radius&quot; type=&quot;number&quot; min=&quot;6&quot; max=&quot;20&quot; value=&quot;10&quot; step=&quot;2&quot; /&gt;&lt;/p&gt;
        &lt;hr /&gt;
        &lt;h2&gt;kernel:&lt;/h2&gt;
          &lt;div&gt;support (K):&amp;nbsp;&lt;div id=&quot;delete-kernel-element&quot; class=&quot;btn btn-square&quot;&gt;-&lt;/div&gt;&lt;div id=&quot;add-kernel-element&quot; class=&quot;btn btn-square&quot;&gt;+&lt;/div&gt;&lt;/div&gt;
          &lt;div&gt;type:
            &lt;input type=&quot;radio&quot; value=&quot;constant&quot; name=&quot;kernel&quot; /&gt;constant
            &lt;input type=&quot;radio&quot; value=&quot;step&quot; name=&quot;kernel&quot; /&gt;step
            &lt;input type=&quot;radio&quot; value=&quot;square&quot; name=&quot;kernel&quot; /&gt;square&lt;br /&gt;
            &lt;input type=&quot;radio&quot; value=&quot;triangle&quot; name=&quot;kernel&quot; /&gt;triangle
            &lt;input type=&quot;radio&quot; value=&quot;gaussian&quot; name=&quot;kernel&quot; /&gt;gaussian
            &lt;input type=&quot;radio&quot; value=&quot;derivative&quot; name=&quot;kernel&quot; /&gt;derivative
          &lt;/div&gt;
        &lt;hr /&gt;
        &lt;h2&gt;signal:&lt;/h2&gt;
          &lt;div&gt;support:&lt;div id=&quot;delete-signal-element&quot; class=&quot;btn btn-square&quot;&gt;-&lt;/div&gt;&lt;div id=&quot;add-signal-element&quot; class=&quot;btn btn-square&quot;&gt;+&lt;/div&gt;&lt;/div&gt;
          &lt;div&gt;type:
            &lt;input type=&quot;radio&quot; value=&quot;sine&quot; name=&quot;signal&quot; /&gt;sine wage
            &lt;input type=&quot;radio&quot; value=&quot;square&quot; name=&quot;signal&quot; /&gt;square
            &lt;input type=&quot;radio&quot; value=&quot;ramp&quot; name=&quot;signal&quot; /&gt;ramp
          &lt;/div&gt;
          &lt;p&gt;padding (p):&amp;nbsp;&lt;input type=&quot;range&quot; min=&quot;0&quot; max=&quot;4&quot; value=&quot;0&quot; step=&quot;1&quot; class=&quot;slider&quot; id=&quot;padding&quot; /&gt;&lt;/p&gt;
        &lt;hr /&gt;
        &lt;h2&gt;convolution:&lt;/h2&gt;
          &lt;p&gt;dilatation (d):&lt;input type=&quot;range&quot; min=&quot;1&quot; max=&quot;3&quot; value=&quot;1&quot; step=&quot;1&quot; class=&quot;slider&quot; id=&quot;dilatation&quot; /&gt;&lt;/p&gt;
          &lt;p&gt;stride (s):&amp;nbsp;&lt;input type=&quot;range&quot; min=&quot;1&quot; max=&quot;3&quot; value=&quot;0&quot; step=&quot;1&quot; class=&quot;slider&quot; id=&quot;stride&quot; /&gt;&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;

   &lt;div id=&quot;math&quot;&gt;&lt;/div&gt;
   &lt;div id=&quot;canvas&quot;&gt;&lt;/div&gt;
   &lt;div id=&quot;player&quot;&gt;
     &lt;div id=&quot;reset&quot; class=&quot;btn&quot;&gt;reset&lt;/div&gt;
     &lt;div id=&quot;prevstep&quot; class=&quot;btn&quot;&gt;previous&lt;/div&gt;
     &lt;div id=&quot;play&quot; class=&quot;btn&quot;&gt;play&lt;/div&gt;
     &lt;div id=&quot;nextstep&quot; class=&quot;btn&quot;&gt;next&lt;/div&gt;
     &lt;div id=&quot;end&quot; class=&quot;btn&quot;&gt;last&lt;/div&gt;
   &lt;/div&gt;

  &lt;script&gt;

  /* Set the width of the side navigation to 250px */
  function openNav(id) {
    let element = document.getElementById(id)
    if (element.style.width == &quot;&quot; || element.style.width == &quot;0px&quot;) {
      element.style.width = &quot;300px&quot;;
    } else {
      element.style.width = &quot;0px&quot;;
    }
  }

  /* Set the width of the side navigation to 0 */
  function closeNav(id) {
    document.getElementById(id).style.width = &quot;0&quot;;
  }

if (window.outerWidth &gt; 900 + 250*2) {
  openNav(&quot;menu&quot;)
}

const width = Math.max(575, Math.min(window.outerWidth, 900));

const scaleW = window.outerWidth/width;
document.querySelector('meta[name=viewport]').setAttribute('content', 'width=device-width,minimum-scale='+scaleW+',maximum-scale='+scaleW+',initial-scale='+scaleW);

let height = 620;

const bkg_color = &quot;#f4f1de&quot;;
const text_color = &quot;#818181&quot;;
const kernel_color = &quot;#C72E38&quot;;
const func_color = &quot;#1d3557&quot;;
const mult_color = &quot;#d94a64&quot;;
const add_color = &quot;#679436&quot;;
const out_color = &quot;#8e576d&quot;;
const duration = 350;


const kernel_line_y = 80;
const func_line_y = 205;
const conv_line_y = 330;
const out_line_y = 490;

const magnitude_max = 50;
const pts_spacing = 25;
const kernel_max_support = 7;
let radius = 10;

let dilatation = 1;
let stride = 1;
let padding = 0;
let step = 0;
let animate = false;

const svg = d3.select(&quot;#canvas&quot;)
    .append(&quot;svg&quot;)
    // .style(&quot;background-color&quot;, &quot;#f4f1de&quot;)
    .attr(&quot;width&quot;, width)
    .attr(&quot;height&quot;, height);

let kernel_fn = d3.range(5).map(i =&gt; ({ y: magnitude_max * (Math.random() * 2 - 1)}));
let func_fn = d3.range(15).map(i =&gt; ({ y: magnitude_max * (Math.random() * 2 - 1)}));
let func_padded_fn = [];
let out_fn = [];

const kernel = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;kernel&quot;);
const conv = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;conv&quot;);
const ops = conv.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;ops&quot;);
const pad_left = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;pad_left&quot;);
const pad_right = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;pad_right&quot;);
const func = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;func&quot;);
const out = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;out&quot;);

function printLabel(label, line_y) {
  svg.append(&quot;text&quot;)
      .attr(&quot;stroke-width&quot;, &quot;2&quot;)
      .attr(&quot;fill&quot;, &quot;#4e5462&quot;)
      .attr(&quot;transform&quot;, &quot;rotate(-90) translate(-&quot; + line_y + &quot;, 20)&quot;)
      .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
      .attr(&quot;font-family&quot;, &quot;monospace&quot;)
      .attr(&quot;dominant-baseline&quot;, &quot;middle&quot;)
      .text(label);
}
printLabel(&quot;kernel&quot;, kernel_line_y);
printLabel(&quot;signal&quot;, func_line_y);
printLabel(&quot;convolution&quot;, conv_line_y);
printLabel(&quot;result&quot;, out_line_y);



function padFunc(fn, pad) {
  let padded = [];
  for (let i = 0; i &lt; pad; i++) {
    padded.push({y: 0});
  }
  padded = padded.concat(fn);
  for (let i = 0; i &lt; pad; i++) {
    padded.push({y: 0});
  }
  return padded;
}

function computeConv(f, g) {
    out_fn = [];
    let s = 0
    while (getConvRightPosition(s) &lt;= func_padded_fn.length) {
        let c = 0;

        try {
            for (let i = 0; i &lt; g.length; i++) {
                c += g[i].y * f[s * stride + i * dilatation].y
            }
            out_fn.push({y: - c / magnitude_max});
        } catch  (error) {
        }
        s += 1;
    }
    let max_value = out_fn.reduce((a, b) =&gt; {return {y: Math.max(a.y, Math.abs(b.y))}}, {y: 0})
    out_fn = out_fn.map(d =&gt; ({y: d.y / max_value.y * magnitude_max}))
    return out_fn.slice(0, step+1);
}

function updateEquation() {
    const equation = document.getElementById(&quot;math&quot;);
    // result
    latex_equation = &quot;\\textcolor{&quot; + out_color + &quot;}{(f * g)}(&quot;+ step + &quot;) &quot;
    latex_equation += &quot;= &quot;
    // sum
    const k = Math.floor((kernel_fn.length - 1) / 2)
    if (kernel_fn.length &gt; 1) {
        latex_equation += &quot;\\textcolor{&quot; + add_color + &quot;}{&quot;
        latex_equation += &quot;\\sum_{i=-k}^{K-k}&quot;
        latex_equation += &quot;}&quot;
    }

    // kernel
    latex_equation += &quot;\\textcolor{&quot; + kernel_color + &quot;}{w_ \\textcolor{&quot; + add_color + &quot;}{i}}&quot;
    // mult
    latex_equation += &quot;\\textcolor{&quot; + mult_color + &quot;}{\\; \\times \\;} &quot;

    // signal
    latex_equation += &quot;\\textcolor{&quot; + func_color + &quot;}{&quot;
    latex_equation += &quot;f_{&quot;
    latex_equation += &quot; \\textcolor{&quot; + text_color + &quot;}{&quot; + step + &quot;} \\times \\textcolor{PaleVioletRed}{s}&quot;
    latex_equation += &quot;- \\textcolor{&quot; + add_color + &quot;}{i}&quot;
    latex_equation += &quot;*\\textcolor{darkorange}{d}&quot;

    const offset = Math.floor(kernel_fn.length / 2) * dilatation - padding
    latex_equation += &quot;+\\textcolor{CadetBlue}{o}&quot;
    latex_equation += &quot;}}&quot;

    // put brackets around operators to reduce spacing
    legend = &quot;\\small &quot;
    legend += &quot;\\textcolor{&quot; + kernel_color + &quot;}{K{=}&quot; + kernel_fn.length +&quot;}&quot;;
    legend += &quot;,\\; p{=}&quot; + padding
    legend += &quot;,\\; \\textcolor{darkorange}{d{=}&quot; + dilatation + &quot;}&quot;
    legend += &quot;,\\; \\textcolor{PaleVioletRed}{s{=}&quot; + stride + &quot;}&quot;
    legend += &quot;,\\; \\textcolor{&quot; + add_color + &quot;}{k{=} \\lfloor (K - 1)/2 \\rfloor {=} &quot; + k + &quot;}&quot;
    legend += &quot;,\\; \\textcolor{CadetBlue}{o{=}\\lfloor K/2 \\rfloor {*} d {-} p {=}&quot; + offset + &quot;}&quot;

    equation.innerHTML = &quot;&lt;p&gt;&quot; + &quot;\\[&quot; + latex_equation + &quot;\\]&quot; + &quot;&lt;/p&gt;&lt;p&gt;&quot; + &quot;\\[&quot; + legend + &quot;\\]&quot; + &quot;&lt;/p&gt;&quot;;
    try {
      MathJax.typeset([&quot;#math&quot;]);
    } catch (error) {
    }
}

dragY = d3.drag()
    .on(&quot;start&quot;, function(d) {
        d3.select(this).attr(&quot;stroke&quot;, &quot;black&quot;);
        d3.select(this).style(&quot;cursor&quot;, null);
        d3.select(&quot;#canvas&quot;).node().classList.add(&quot;grabbing&quot;);;
    })
    .on(&quot;drag&quot;, function(d) {
        y = d3.event.y;
        y = Math.max(-magnitude_max, y);
        y = Math.min(+magnitude_max, y);
        d.y = y;

        update();
    })
    .on(&quot;end&quot;, function(d) {
        d3.select(this).attr(&quot;stroke&quot;, null);
        d3.select(this).style(&quot;cursor&quot;, &quot;pointer&quot;);
        d3.select(&quot;#canvas&quot;).node().classList.remove(&quot;grabbing&quot;);;
    })

//// Draw X axis line
function updateXaxis(root, n, dilatation) {
    if (root.select(&quot;#hline&quot;).empty()) {
        root.append(&quot;line&quot;)
            .attr(&quot;id&quot;, &quot;hline&quot;)
            .attr(&quot;y1&quot;, 0)
            .attr(&quot;y2&quot;, 0)
            .attr(&quot;stroke&quot;, &quot;gray&quot;)
            .attr(&quot;stroke-width&quot;, 2);
    }
    root.select(&quot;#hline&quot;)
        .transition()
        .duration(animate * duration)
        .attr(&quot;x1&quot;, 0)
        .attr(&quot;x2&quot;, n * pts_spacing * dilatation);
}

//// Update group top right corner positions
function updateCenteredLayout(root, n, line_y, dilatation) {
    const x = (width - n * pts_spacing * dilatation) / 2;
    root.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + x + &quot;,&quot; + line_y + &quot;)&quot;);
}

function updatePadLeft() {
    const right = (width - func_fn.length * pts_spacing) / 2;
    const left = right - padding * pts_spacing;
    pad_left.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + left + &quot;,&quot; + func_line_y + &quot;)&quot;);
}

function updatePadRight() {
    const left = (width + func_fn.length * pts_spacing) / 2;
    pad_right.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + left + &quot;,&quot; + func_line_y + &quot;)&quot;);
}

function updateConvLayout() {
    let x = (width - func_padded_fn.length * pts_spacing) / 2;
    x += pts_spacing * step * stride;
    x -= pts_spacing * (dilatation - 1) / 2;
    conv.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + x + &quot;,&quot; + conv_line_y + &quot;)&quot;);
}

function updateOutputLayout() {
    let x = (width - func_padded_fn.length * pts_spacing) / 2;
    x += pts_spacing * ((Math.ceil(kernel_fn.length / 2) - 1) * dilatation);
    x -= pts_spacing * (stride - 1) / 2 ;
    out.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + x + &quot;,&quot; + out_line_y + &quot;)&quot;);
}

//// Drawing primitives
function drawPadding(root, n) {
    // data binding
    const cercles = root.selectAll(&quot;circle&quot;).data(d3.range(n));
    // remove elements no longer in data
    cercles.exit().transition().duration(animate * duration / 2).attr(&quot;r&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_circles = cercles
        .enter()
        .append(&quot;circle&quot;)
        .attr(&quot;fill&quot;, &quot;lightgray&quot;)
        .attr(&quot;r&quot;, 0)
        .transition()
        .duration(animate * duration * 2)
        .attr(&quot;r&quot;, radius)
    // Operates on both new and old elements
    cercles
        .merge(new_circles)
        .attr(&quot;cx&quot;, function(i) {
            return pts_spacing * (i + 0.5);
        })
        .attr(&quot;cy&quot;, 0);
}

function drawFunction(root, data, dilatation, color, is_interactive) {
    // data binding
    const vlines = root.selectAll(&quot;#vline&quot;).data(data);
    // remove elements no longer in data
    vlines.exit().transition().duration(animate * duration / 2).attr(&quot;stroke-width&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_lines = vlines
        .enter()
        .append(&quot;line&quot;)
        .attr(&quot;id&quot;, &quot;vline&quot;)
        .attr(&quot;stroke&quot;, &quot;gray&quot;)
        .attr(&quot;stroke-width&quot;, 2)
        .attr(&quot;y1&quot;, 0)
        .attr(&quot;x1&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;x2&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        });
    // Operates on both new and old elements
    vlines
        .merge(new_lines)
        .attr(&quot;y2&quot;, function(d, i) {
            return d.y;
        })
        .transition()
        .duration(animate * duration)
        .attr(&quot;x1&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;x2&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        });


    // data binding
    const cercles = root.selectAll(&quot;circle&quot;).data(data);
    // remove elements no longer in data
    cercles.exit().transition().duration(animate * duration / 2).attr(&quot;r&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_circles = cercles
        .enter()
        .append(&quot;circle&quot;)
        .attr(&quot;fill&quot;, color)
        .attr(&quot;cx&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;r&quot;, 0)
    if (is_interactive) {
        new_circles
            .style(&quot;cursor&quot;, &quot;pointer&quot;)
            .call(dragY)
            .on(&quot;dblclick&quot;, function(d) {
                d.y = d.y ? 0 : - magnitude_max;
                update()
            });
    }

    // Operates on both new and old elements
    cercles
        .merge(new_circles)
        .attr(&quot;cy&quot;, function(d, i) {
            return d.y;
        })
        .transition()
        .duration(animate * duration)
        .attr(&quot;cx&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;r&quot;, radius);
}

function drawConvOps(root, data, dilatation) {
    // data binding
    const mult_lines = root.selectAll(&quot;#multline&quot;).data(data);
    // remove elements no longer in data
    mult_lines.exit().transition().duration(animate * duration / 2).attr(&quot;stroke-width&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_mutl_lines = mult_lines
        .enter()
        .append(&quot;line&quot;)
        .attr(&quot;id&quot;, &quot;multline&quot;)
        .attr(&quot;stroke&quot;, mult_color)
        .attr(&quot;stroke-width&quot;, 0)
        .attr(&quot;y1&quot;, 0)
        .attr(&quot;y2&quot;, 0)
        .attr(&quot;x1&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;x2&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .transition(&quot;fade in&quot;)
        .duration(animate * duration / 2)
        .attr(&quot;stroke-width&quot;, 1.25)
        .attr(&quot;y2&quot;, -125);
    // Operates on both new and old elements
    mult_lines
        .transition()
        .duration(animate * duration)
        .attr(&quot;x1&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;x2&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })

    // data binding
    const add_lines = root.selectAll(&quot;#addline&quot;).data(data);
    // remove elements no longer in data
    add_lines.exit().transition().duration(animate * duration / 2).attr(&quot;stroke-width&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_add_lines = add_lines
        .enter()
        .append(&quot;path&quot;)
        .attr(&quot;id&quot;, &quot;addline&quot;)
        .attr(&quot;stroke&quot;, add_color)
        .attr(&quot;fill&quot;, &quot;none&quot;);

    // Operates on both new and old elements
    add_lines
        .merge(new_add_lines)
        .transition()
        .duration(animate* duration)
        .attr(&quot;d&quot;, function(d, i) {
            const x_pts = pts_spacing * (i + 0.5) * dilatation;
            const x_middle = pts_spacing * (Math.ceil(data.length / 2) - 0.5) * dilatation;
            const points = [
                [x_pts, Math.max(d.y, -radius / 2) + 10],
                [x_pts, magnitude_max + 10],
                [x_pts, magnitude_max + 20],
                [x_middle, magnitude_max + 20],
                [x_middle, magnitude_max + 25],
                [x_middle, magnitude_max + 150 - magnitude_max],
            ];

            const line = d3
                .line()
                .x(d =&gt; d[0])
                .y(d =&gt; d[1])
                .curve(d3.curveBundle.beta(1));
            return line(points);
        });

    new_add_lines
        .attr(&quot;stroke-width&quot;, 0)
        .transition()
        .duration(animate * duration)
        .attr(&quot;stroke-width&quot;, 1.25);
}


function update() {
    func_padded_fn = padFunc(func_fn, padding);
    // kernel
    updateCenteredLayout(kernel, kernel_fn.length, kernel_line_y, dilatation);
    updateXaxis(kernel, kernel_fn.length, dilatation);
    drawFunction(kernel, kernel_fn, dilatation, kernel_color, true);

    // function
    updatePadLeft();
    updateXaxis(pad_left, padding, 1);
    drawPadding(pad_left, padding);

    updateCenteredLayout(func, func_fn.length, func_line_y, 1);
    updateXaxis(func, func_fn.length, 1);
    drawFunction(func, func_fn, 1, func_color, true);

    updatePadRight();
    updateXaxis(pad_right, padding, 1);
    drawPadding(pad_right, padding);

    // conv-ops
    updateConvLayout();
    // reverse kernel in a non destructive way by making a copy
    const reversed_kernel_fn = [...kernel_fn].reverse();
    updateXaxis(conv, kernel_fn.length, dilatation);
    drawFunction(conv, reversed_kernel_fn, dilatation, kernel_color, true);
    drawConvOps(ops, reversed_kernel_fn, dilatation);

    // result
    out_fn = computeConv(func_padded_fn, reversed_kernel_fn);
    updateOutputLayout();
    updateXaxis(out, out_fn.length, stride);
    drawFunction(out, out_fn, stride, out_color, false);
}
update();
updateEquation();
animate = true;


function getConvRightPosition(step) {
    return step * stride + (kernel_fn.length - 1) * dilatation + 1;
}

//// User input
d3.select(&quot;#radius&quot;).on(&quot;input&quot;, function() {
    radius = Math.max(6, Math.min(this.value, 20));
    this.value = radius;
    update();
});

d3.select(&quot;#dilatation&quot;)
    .on(&quot;input&quot;, function() {
        dilatation = Math.min(Math.max(this.min, this.value), this.max);
        this.value = dilatation;
        while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
            step -= 1;
        }
        update();
        updateEquation();
    })

d3.select(&quot;#stride&quot;)
    .on(&quot;input&quot;, function() {
        stride = Math.min(Math.max(this.min, this.value), this.max);
        this.value = stride;
        while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
            step -= 1;
        }
        update();
        updateEquation();
    });

d3.select(&quot;#padding&quot;)
    .on(&quot;input&quot;, function() {
        padding = Math.min(Math.max(this.min, this.value), this.max);
        this.value = padding;
        while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_fn.length + 2 *padding) {
            step -= 1;
        }
        update();
        updateEquation();
    });

d3.select(&quot;#prevstep&quot;)
    .on(&quot;click&quot;, function() {
        if (step &gt; 0) {
            step -= 1;
            update();
            updateEquation();
        }
    });
d3.select(&quot;#nextstep&quot;)
    .on(&quot;click&quot;, function() {
        if (getConvRightPosition(step) + stride &lt;= func_padded_fn.length) {
            step += 1;
            update();
            updateEquation();
        }
    });

d3.select(&quot;#add-kernel-element&quot;)
    .on(&quot;click&quot;, function() {
        if (kernel_fn.length &lt; kernel_max_support) {
            kernel_fn.push({ y: 0 });
            while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
                step -= 1;
            }
            update();
            updateEquation();
        }
    });
d3.select(&quot;#delete-kernel-element&quot;)
    .on(&quot;click&quot;, function() {
        if (kernel_fn.length &gt; 1) {
            kernel_fn.pop();
            update();
        }
    });

d3.selectAll(&quot;input[name='kernel']&quot;).on(&quot;change&quot;, function(){
    if (this.value == &quot;constant&quot;) {
        kernel_fn = [{y:-magnitude_max}, {y:-magnitude_max}, {y:-magnitude_max}];
    } else if (this.value == &quot;step&quot;) {
        kernel_fn = [{y:0}, {y:0}, {y:-magnitude_max}, {y:-magnitude_max}, {y:-magnitude_max}];
    } else if (this.value == &quot;square&quot;) {
        kernel_fn = [{y:0}, {y:-magnitude_max}, {y:-magnitude_max}, {y:-magnitude_max}, {y:0}];
    } else if (this.value == &quot;triangle&quot;) {
        kernel_fn = [{y:-magnitude_max / 3}, {y:-magnitude_max * 2 / 3}, {y:-magnitude_max}, {y:-magnitude_max * 2 / 3}, {y:-magnitude_max / 3}];
    } else if (this.value == &quot;gaussian&quot;) {
        kernel_fn = [{y:-magnitude_max * 4 / 19}, {y:-magnitude_max * 10 / 18 }, {y:-magnitude_max * 16 / 19}, {y:-magnitude_max}, {y:-magnitude_max * 16 / 19}, {y:-magnitude_max * 10 / 19}, {y:-magnitude_max * 4 / 19}];
    } else if (this.value == &quot;derivative&quot;) {
        kernel_fn = [{y:-magnitude_max}, {y:magnitude_max}];
    }
    while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
        step -= 1;
    }
    update();
    updateEquation();
});

d3.select(&quot;#add-signal-element&quot;)
    .on(&quot;click&quot;, function() {
          func_fn.push({ y: 0 });
          update();
    });
d3.select(&quot;#delete-signal-element&quot;)
    .on(&quot;click&quot;, function() {
          func_fn.pop({ y: 0 });
          func_padded_fn = padFunc(func_fn, padding);
          while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
              step -= 1;
          }
          update();
          updateEquation();
    });
d3.selectAll(&quot;input[name='signal']&quot;).on(&quot;change&quot;, function(){
    if (this.value == &quot;sine&quot;) {
        new_fn = []
        for (let i = 0; i &lt; func_fn.length; i++) {
            new_fn.push({y: Math.cos(i/1.3) * magnitude_max})
        }
        func_fn = new_fn;
    } else if (this.value == &quot;square&quot;) {
        new_fn = []
        for (let i = 0; i &lt; func_fn.length; i++) {
            console.log()
            new_fn.push({y: - (Math.floor(i / 5) + 1)% 2 * magnitude_max})
        }
        func_fn = new_fn;
    } else if (this.value == &quot;ramp&quot;) {
        new_fn = []
        for (let i = 0; i &lt; func_fn.length; i++) {
            new_fn.push({y: - ((i / 5) % 1 * 5/4 - 0.5) * 2 * magnitude_max})
        }
        func_fn = new_fn;
    }
    while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
        step -= 1;
    }
    update();
    updateEquation();
});


d3.select(&quot;#play&quot;)
    .on(&quot;click&quot;, function() {
        d3.selectAll(&quot;*&quot;).interrupt();
        svg.transition().on(&quot;end&quot;, function repeat(d){
            if (getConvRightPosition(step) + stride &lt;= func_padded_fn.length) {
                step += 1;
                update();
                updateEquation();
                d3.active(this).transition().delay(600).on(&quot;start&quot;, repeat);
            }
        })
    });
d3.select(&quot;#reset&quot;)
    .on(&quot;click&quot;, function() {
        d3.selectAll(&quot;*&quot;).interrupt();
        step = 0;
        update();
        updateEquation();
    });
d3.select(&quot;#end&quot;)
    .on(&quot;click&quot;, function() {
        d3.selectAll(&quot;*&quot;).interrupt();
        while (getConvRightPosition(step) + stride &lt;= func_padded_fn.length) {
            step += 1;
        }
        update();
        updateEquation();
    });
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;

</description>
        
          <description>&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;&quot; /&gt;
  &lt;script src=&quot;https://d3js.org/d3.v4.min.js&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
  &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
  MathJax = {
    loader: {load: ['[tex]/color']},
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)'], ['\\[', '\\]']],
      packages: {'[+]': ['color']}
    },
    svg: {
      fontCache: 'global'
    }
  };

  &lt;/script&gt;
  &lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/input/tex/extensions/colorV2.js&quot; charset=&quot;UTF-8&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/input/tex/extensions/color.js&quot; charset=&quot;UTF-8&quot;&gt;&lt;/script&gt;
  &lt;style&gt;
    body {
      font-family: monospace;
      font-size: 12px;
      color: #818181;
      background-color: #f4f1de;
      /* background-color: #eeeeee; */
      margin: auto;
      height: 100%;
      text-align: center;
      /* width: 30%; */
      overscroll-behavior-y: none;
    }

    h1, h2{
        font-weight: 1.2;
        color: #505050;
    }
    h2 {
      text-align: left;
      margin-bottom: 0.5em;
    }
    hr {
      color: white;
      border-width: 1px;
    }


    .btn-square {
      height: 1.5em !important;
      width: 1.5em  !important;
    }
    input[type=radio]{
      vertical-align: text-bottom;
      line-height: 0.4em;
    }
    input[type=range]{
      vertical-align: middle;
      line-height: 1.6em;
      width: 120;
    }
    input[type=number]{
      width: 56px;
    }

    #math {
      width: 100%;
      height: 90px;
      font-size: 1.25em;
    }
    .menu {
      /* margin-left: 5px; */
      /* margin-right: 5px; */
      padding-top: 12px;
      padding-bottom: 12px;
      border-bottom: 1px solid lightgray;
    }
    .menu h1, .menu .option {
      display: inline;
    }
    .option {
        position:fixed;
        left: 8px;
        top: 2px;
    }

    .rotate270 {
        writing-mode: vertical-rl;
        transform: rotate(180deg);
        text-align: right;
    }
    .menu .btn {
      /* height:105px; */
      z-index: 2; /* Stay on top */
    }

    .btn{
        display: inline-block;
        padding: 6px 5px;
        margin-bottom: 0;
        font-size: 14px;
        text-align: center;
        /* font-weight: 400; */
        line-height: 1.42857143;
        white-space: nowrap;
        vertical-align: middle;
        -ms-touch-action: manipulation;
        touch-action: manipulation;
        cursor: pointer;
        -webkit-user-select: none;
        -moz-user-select: none;
        -ms-user-select: none;
        user-select: none;
        background-image: none;
        border: 1px solid transparent;
        border-radius: 4px;
        text-decoration: none;
        margin-top: 4px;
        margin-bottom : 4px;
        height: 2em;

        color: #4e5462;
        background-color: #fff;
        border-color: #ccc;
    }
    .btn:hover {
      background-color: #eee;
      border-color: #aaa;
    }

    #result-btn {
        margin-top: 34px !important;
        cursor: default !important;
        border-bottom: 0px !important;
        border-top: 0px !important;
        border-right: 0px !important;
    }
    #result-btn:hover {
        border-bottom: 0px !important;
        border-top: 0px !important;
        border-right: 0px !important;
        background-color: #fff !important;
        border-color: #ccc !important ;
    }

    /* The side navigation menu */
   .sidenav {
       height: auto; /* 100% Full-height */
       width: 0; /* 0 width - change this with JavaScript */
       position: fixed; /* Stay in place */
       z-index: 10; /* Stay on top */
       background-color: #eee; /* Black*/
       overflow-x: hidden; /* Disable horizontal scroll */
       transition: 0.5s; /* 0.5 second transition effect to slide in the sidenav */
       margin-left: 8px;
       margin-top: -6px;
       box-shadow: 0px 0px 0px 1px lightgray inset;
       /* border: 1px solid lightgray; */
       box-sizing: border-box;
   }

   /* The navigation menu links */
   .sidenav a {
       color: #818181;
       display: block;
       transition: 0.3s;
   }

   /* When you mouse over the navigation links, change their color */
   .sidenav a:hover {
     color: #111;
   }

   /* Position and style the close button (top right corner) */
   .sidenav .closebtn {
       position: absolute;
       top: 8px;
       right: 8px;
       font-size: 2em;
       margin-left: 20px;
   }

   /* Style page content - use this if you want to push the page content to the right when you open the side navigation */
   #main {
     transition: margin-left .5s;
     padding: 20px;
   }

   /* On smaller screens, where height is less than 450px, change the style of the sidenav (less padding and a smaller font size) */
   @media screen and (max-height: 450px) {
     .sidenav {padding-top: 15px;}
     .sidenav a {font-size: 18px;}
   }

   .nav-wrapper {
     margin: 10px;
     width: 280px;
   }

   .grabbing {
     cursor: move;
   }

   #player .btn {
     width: 80px;
     height: 20px;
   }


  &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;div class=&quot;menu&quot;&gt;
    &lt;h1&gt;Convolution Sandbox&lt;/h1&gt;
    &lt;div class=&quot;option btn&quot; onclick=&quot;openNav('menu')&quot;&gt;options&lt;/div&gt;
    &lt;div id=&quot;menu&quot; class=&quot;sidenav&quot;&gt;
      &lt;div class=&quot;nav-wrapper&quot;&gt;
        &lt;a href=&quot;javascript:void(0)&quot; class=&quot;closebtn&quot; onclick=&quot;closeNav('menu')&quot;&gt;&amp;times;&lt;/a&gt;
        &lt;h2&gt;General:&lt;/h2&gt;
          &lt;p&gt;sphere radius:&amp;nbsp;&lt;input id=&quot;radius&quot; type=&quot;number&quot; min=&quot;6&quot; max=&quot;20&quot; value=&quot;10&quot; step=&quot;2&quot; /&gt;&lt;/p&gt;
        &lt;hr /&gt;
        &lt;h2&gt;kernel:&lt;/h2&gt;
          &lt;div&gt;support (K):&amp;nbsp;&lt;div id=&quot;delete-kernel-element&quot; class=&quot;btn btn-square&quot;&gt;-&lt;/div&gt;&lt;div id=&quot;add-kernel-element&quot; class=&quot;btn btn-square&quot;&gt;+&lt;/div&gt;&lt;/div&gt;
          &lt;div&gt;type:
            &lt;input type=&quot;radio&quot; value=&quot;constant&quot; name=&quot;kernel&quot; /&gt;constant
            &lt;input type=&quot;radio&quot; value=&quot;step&quot; name=&quot;kernel&quot; /&gt;step
            &lt;input type=&quot;radio&quot; value=&quot;square&quot; name=&quot;kernel&quot; /&gt;square&lt;br /&gt;
            &lt;input type=&quot;radio&quot; value=&quot;triangle&quot; name=&quot;kernel&quot; /&gt;triangle
            &lt;input type=&quot;radio&quot; value=&quot;gaussian&quot; name=&quot;kernel&quot; /&gt;gaussian
            &lt;input type=&quot;radio&quot; value=&quot;derivative&quot; name=&quot;kernel&quot; /&gt;derivative
          &lt;/div&gt;
        &lt;hr /&gt;
        &lt;h2&gt;signal:&lt;/h2&gt;
          &lt;div&gt;support:&lt;div id=&quot;delete-signal-element&quot; class=&quot;btn btn-square&quot;&gt;-&lt;/div&gt;&lt;div id=&quot;add-signal-element&quot; class=&quot;btn btn-square&quot;&gt;+&lt;/div&gt;&lt;/div&gt;
          &lt;div&gt;type:
            &lt;input type=&quot;radio&quot; value=&quot;sine&quot; name=&quot;signal&quot; /&gt;sine wage
            &lt;input type=&quot;radio&quot; value=&quot;square&quot; name=&quot;signal&quot; /&gt;square
            &lt;input type=&quot;radio&quot; value=&quot;ramp&quot; name=&quot;signal&quot; /&gt;ramp
          &lt;/div&gt;
          &lt;p&gt;padding (p):&amp;nbsp;&lt;input type=&quot;range&quot; min=&quot;0&quot; max=&quot;4&quot; value=&quot;0&quot; step=&quot;1&quot; class=&quot;slider&quot; id=&quot;padding&quot; /&gt;&lt;/p&gt;
        &lt;hr /&gt;
        &lt;h2&gt;convolution:&lt;/h2&gt;
          &lt;p&gt;dilatation (d):&lt;input type=&quot;range&quot; min=&quot;1&quot; max=&quot;3&quot; value=&quot;1&quot; step=&quot;1&quot; class=&quot;slider&quot; id=&quot;dilatation&quot; /&gt;&lt;/p&gt;
          &lt;p&gt;stride (s):&amp;nbsp;&lt;input type=&quot;range&quot; min=&quot;1&quot; max=&quot;3&quot; value=&quot;0&quot; step=&quot;1&quot; class=&quot;slider&quot; id=&quot;stride&quot; /&gt;&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;

   &lt;div id=&quot;math&quot;&gt;&lt;/div&gt;
   &lt;div id=&quot;canvas&quot;&gt;&lt;/div&gt;
   &lt;div id=&quot;player&quot;&gt;
     &lt;div id=&quot;reset&quot; class=&quot;btn&quot;&gt;reset&lt;/div&gt;
     &lt;div id=&quot;prevstep&quot; class=&quot;btn&quot;&gt;previous&lt;/div&gt;
     &lt;div id=&quot;play&quot; class=&quot;btn&quot;&gt;play&lt;/div&gt;
     &lt;div id=&quot;nextstep&quot; class=&quot;btn&quot;&gt;next&lt;/div&gt;
     &lt;div id=&quot;end&quot; class=&quot;btn&quot;&gt;last&lt;/div&gt;
   &lt;/div&gt;

  &lt;script&gt;

  /* Set the width of the side navigation to 250px */
  function openNav(id) {
    let element = document.getElementById(id)
    if (element.style.width == &quot;&quot; || element.style.width == &quot;0px&quot;) {
      element.style.width = &quot;300px&quot;;
    } else {
      element.style.width = &quot;0px&quot;;
    }
  }

  /* Set the width of the side navigation to 0 */
  function closeNav(id) {
    document.getElementById(id).style.width = &quot;0&quot;;
  }

if (window.outerWidth &gt; 900 + 250*2) {
  openNav(&quot;menu&quot;)
}

const width = Math.max(575, Math.min(window.outerWidth, 900));

const scaleW = window.outerWidth/width;
document.querySelector('meta[name=viewport]').setAttribute('content', 'width=device-width,minimum-scale='+scaleW+',maximum-scale='+scaleW+',initial-scale='+scaleW);

let height = 620;

const bkg_color = &quot;#f4f1de&quot;;
const text_color = &quot;#818181&quot;;
const kernel_color = &quot;#C72E38&quot;;
const func_color = &quot;#1d3557&quot;;
const mult_color = &quot;#d94a64&quot;;
const add_color = &quot;#679436&quot;;
const out_color = &quot;#8e576d&quot;;
const duration = 350;


const kernel_line_y = 80;
const func_line_y = 205;
const conv_line_y = 330;
const out_line_y = 490;

const magnitude_max = 50;
const pts_spacing = 25;
const kernel_max_support = 7;
let radius = 10;

let dilatation = 1;
let stride = 1;
let padding = 0;
let step = 0;
let animate = false;

const svg = d3.select(&quot;#canvas&quot;)
    .append(&quot;svg&quot;)
    // .style(&quot;background-color&quot;, &quot;#f4f1de&quot;)
    .attr(&quot;width&quot;, width)
    .attr(&quot;height&quot;, height);

let kernel_fn = d3.range(5).map(i =&gt; ({ y: magnitude_max * (Math.random() * 2 - 1)}));
let func_fn = d3.range(15).map(i =&gt; ({ y: magnitude_max * (Math.random() * 2 - 1)}));
let func_padded_fn = [];
let out_fn = [];

const kernel = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;kernel&quot;);
const conv = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;conv&quot;);
const ops = conv.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;ops&quot;);
const pad_left = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;pad_left&quot;);
const pad_right = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;pad_right&quot;);
const func = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;func&quot;);
const out = svg.append(&quot;g&quot;).attr(&quot;id&quot;, &quot;out&quot;);

function printLabel(label, line_y) {
  svg.append(&quot;text&quot;)
      .attr(&quot;stroke-width&quot;, &quot;2&quot;)
      .attr(&quot;fill&quot;, &quot;#4e5462&quot;)
      .attr(&quot;transform&quot;, &quot;rotate(-90) translate(-&quot; + line_y + &quot;, 20)&quot;)
      .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
      .attr(&quot;font-family&quot;, &quot;monospace&quot;)
      .attr(&quot;dominant-baseline&quot;, &quot;middle&quot;)
      .text(label);
}
printLabel(&quot;kernel&quot;, kernel_line_y);
printLabel(&quot;signal&quot;, func_line_y);
printLabel(&quot;convolution&quot;, conv_line_y);
printLabel(&quot;result&quot;, out_line_y);



function padFunc(fn, pad) {
  let padded = [];
  for (let i = 0; i &lt; pad; i++) {
    padded.push({y: 0});
  }
  padded = padded.concat(fn);
  for (let i = 0; i &lt; pad; i++) {
    padded.push({y: 0});
  }
  return padded;
}

function computeConv(f, g) {
    out_fn = [];
    let s = 0
    while (getConvRightPosition(s) &lt;= func_padded_fn.length) {
        let c = 0;

        try {
            for (let i = 0; i &lt; g.length; i++) {
                c += g[i].y * f[s * stride + i * dilatation].y
            }
            out_fn.push({y: - c / magnitude_max});
        } catch  (error) {
        }
        s += 1;
    }
    let max_value = out_fn.reduce((a, b) =&gt; {return {y: Math.max(a.y, Math.abs(b.y))}}, {y: 0})
    out_fn = out_fn.map(d =&gt; ({y: d.y / max_value.y * magnitude_max}))
    return out_fn.slice(0, step+1);
}

function updateEquation() {
    const equation = document.getElementById(&quot;math&quot;);
    // result
    latex_equation = &quot;\\textcolor{&quot; + out_color + &quot;}{(f * g)}(&quot;+ step + &quot;) &quot;
    latex_equation += &quot;= &quot;
    // sum
    const k = Math.floor((kernel_fn.length - 1) / 2)
    if (kernel_fn.length &gt; 1) {
        latex_equation += &quot;\\textcolor{&quot; + add_color + &quot;}{&quot;
        latex_equation += &quot;\\sum_{i=-k}^{K-k}&quot;
        latex_equation += &quot;}&quot;
    }

    // kernel
    latex_equation += &quot;\\textcolor{&quot; + kernel_color + &quot;}{w_ \\textcolor{&quot; + add_color + &quot;}{i}}&quot;
    // mult
    latex_equation += &quot;\\textcolor{&quot; + mult_color + &quot;}{\\; \\times \\;} &quot;

    // signal
    latex_equation += &quot;\\textcolor{&quot; + func_color + &quot;}{&quot;
    latex_equation += &quot;f_{&quot;
    latex_equation += &quot; \\textcolor{&quot; + text_color + &quot;}{&quot; + step + &quot;} \\times \\textcolor{PaleVioletRed}{s}&quot;
    latex_equation += &quot;- \\textcolor{&quot; + add_color + &quot;}{i}&quot;
    latex_equation += &quot;*\\textcolor{darkorange}{d}&quot;

    const offset = Math.floor(kernel_fn.length / 2) * dilatation - padding
    latex_equation += &quot;+\\textcolor{CadetBlue}{o}&quot;
    latex_equation += &quot;}}&quot;

    // put brackets around operators to reduce spacing
    legend = &quot;\\small &quot;
    legend += &quot;\\textcolor{&quot; + kernel_color + &quot;}{K{=}&quot; + kernel_fn.length +&quot;}&quot;;
    legend += &quot;,\\; p{=}&quot; + padding
    legend += &quot;,\\; \\textcolor{darkorange}{d{=}&quot; + dilatation + &quot;}&quot;
    legend += &quot;,\\; \\textcolor{PaleVioletRed}{s{=}&quot; + stride + &quot;}&quot;
    legend += &quot;,\\; \\textcolor{&quot; + add_color + &quot;}{k{=} \\lfloor (K - 1)/2 \\rfloor {=} &quot; + k + &quot;}&quot;
    legend += &quot;,\\; \\textcolor{CadetBlue}{o{=}\\lfloor K/2 \\rfloor {*} d {-} p {=}&quot; + offset + &quot;}&quot;

    equation.innerHTML = &quot;&lt;p&gt;&quot; + &quot;\\[&quot; + latex_equation + &quot;\\]&quot; + &quot;&lt;/p&gt;&lt;p&gt;&quot; + &quot;\\[&quot; + legend + &quot;\\]&quot; + &quot;&lt;/p&gt;&quot;;
    try {
      MathJax.typeset([&quot;#math&quot;]);
    } catch (error) {
    }
}

dragY = d3.drag()
    .on(&quot;start&quot;, function(d) {
        d3.select(this).attr(&quot;stroke&quot;, &quot;black&quot;);
        d3.select(this).style(&quot;cursor&quot;, null);
        d3.select(&quot;#canvas&quot;).node().classList.add(&quot;grabbing&quot;);;
    })
    .on(&quot;drag&quot;, function(d) {
        y = d3.event.y;
        y = Math.max(-magnitude_max, y);
        y = Math.min(+magnitude_max, y);
        d.y = y;

        update();
    })
    .on(&quot;end&quot;, function(d) {
        d3.select(this).attr(&quot;stroke&quot;, null);
        d3.select(this).style(&quot;cursor&quot;, &quot;pointer&quot;);
        d3.select(&quot;#canvas&quot;).node().classList.remove(&quot;grabbing&quot;);;
    })

//// Draw X axis line
function updateXaxis(root, n, dilatation) {
    if (root.select(&quot;#hline&quot;).empty()) {
        root.append(&quot;line&quot;)
            .attr(&quot;id&quot;, &quot;hline&quot;)
            .attr(&quot;y1&quot;, 0)
            .attr(&quot;y2&quot;, 0)
            .attr(&quot;stroke&quot;, &quot;gray&quot;)
            .attr(&quot;stroke-width&quot;, 2);
    }
    root.select(&quot;#hline&quot;)
        .transition()
        .duration(animate * duration)
        .attr(&quot;x1&quot;, 0)
        .attr(&quot;x2&quot;, n * pts_spacing * dilatation);
}

//// Update group top right corner positions
function updateCenteredLayout(root, n, line_y, dilatation) {
    const x = (width - n * pts_spacing * dilatation) / 2;
    root.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + x + &quot;,&quot; + line_y + &quot;)&quot;);
}

function updatePadLeft() {
    const right = (width - func_fn.length * pts_spacing) / 2;
    const left = right - padding * pts_spacing;
    pad_left.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + left + &quot;,&quot; + func_line_y + &quot;)&quot;);
}

function updatePadRight() {
    const left = (width + func_fn.length * pts_spacing) / 2;
    pad_right.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + left + &quot;,&quot; + func_line_y + &quot;)&quot;);
}

function updateConvLayout() {
    let x = (width - func_padded_fn.length * pts_spacing) / 2;
    x += pts_spacing * step * stride;
    x -= pts_spacing * (dilatation - 1) / 2;
    conv.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + x + &quot;,&quot; + conv_line_y + &quot;)&quot;);
}

function updateOutputLayout() {
    let x = (width - func_padded_fn.length * pts_spacing) / 2;
    x += pts_spacing * ((Math.ceil(kernel_fn.length / 2) - 1) * dilatation);
    x -= pts_spacing * (stride - 1) / 2 ;
    out.transition()
        .duration(animate * duration)
        .attr(&quot;transform&quot;, &quot;translate(&quot; + x + &quot;,&quot; + out_line_y + &quot;)&quot;);
}

//// Drawing primitives
function drawPadding(root, n) {
    // data binding
    const cercles = root.selectAll(&quot;circle&quot;).data(d3.range(n));
    // remove elements no longer in data
    cercles.exit().transition().duration(animate * duration / 2).attr(&quot;r&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_circles = cercles
        .enter()
        .append(&quot;circle&quot;)
        .attr(&quot;fill&quot;, &quot;lightgray&quot;)
        .attr(&quot;r&quot;, 0)
        .transition()
        .duration(animate * duration * 2)
        .attr(&quot;r&quot;, radius)
    // Operates on both new and old elements
    cercles
        .merge(new_circles)
        .attr(&quot;cx&quot;, function(i) {
            return pts_spacing * (i + 0.5);
        })
        .attr(&quot;cy&quot;, 0);
}

function drawFunction(root, data, dilatation, color, is_interactive) {
    // data binding
    const vlines = root.selectAll(&quot;#vline&quot;).data(data);
    // remove elements no longer in data
    vlines.exit().transition().duration(animate * duration / 2).attr(&quot;stroke-width&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_lines = vlines
        .enter()
        .append(&quot;line&quot;)
        .attr(&quot;id&quot;, &quot;vline&quot;)
        .attr(&quot;stroke&quot;, &quot;gray&quot;)
        .attr(&quot;stroke-width&quot;, 2)
        .attr(&quot;y1&quot;, 0)
        .attr(&quot;x1&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;x2&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        });
    // Operates on both new and old elements
    vlines
        .merge(new_lines)
        .attr(&quot;y2&quot;, function(d, i) {
            return d.y;
        })
        .transition()
        .duration(animate * duration)
        .attr(&quot;x1&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;x2&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        });


    // data binding
    const cercles = root.selectAll(&quot;circle&quot;).data(data);
    // remove elements no longer in data
    cercles.exit().transition().duration(animate * duration / 2).attr(&quot;r&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_circles = cercles
        .enter()
        .append(&quot;circle&quot;)
        .attr(&quot;fill&quot;, color)
        .attr(&quot;cx&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;r&quot;, 0)
    if (is_interactive) {
        new_circles
            .style(&quot;cursor&quot;, &quot;pointer&quot;)
            .call(dragY)
            .on(&quot;dblclick&quot;, function(d) {
                d.y = d.y ? 0 : - magnitude_max;
                update()
            });
    }

    // Operates on both new and old elements
    cercles
        .merge(new_circles)
        .attr(&quot;cy&quot;, function(d, i) {
            return d.y;
        })
        .transition()
        .duration(animate * duration)
        .attr(&quot;cx&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;r&quot;, radius);
}

function drawConvOps(root, data, dilatation) {
    // data binding
    const mult_lines = root.selectAll(&quot;#multline&quot;).data(data);
    // remove elements no longer in data
    mult_lines.exit().transition().duration(animate * duration / 2).attr(&quot;stroke-width&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_mutl_lines = mult_lines
        .enter()
        .append(&quot;line&quot;)
        .attr(&quot;id&quot;, &quot;multline&quot;)
        .attr(&quot;stroke&quot;, mult_color)
        .attr(&quot;stroke-width&quot;, 0)
        .attr(&quot;y1&quot;, 0)
        .attr(&quot;y2&quot;, 0)
        .attr(&quot;x1&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;x2&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .transition(&quot;fade in&quot;)
        .duration(animate * duration / 2)
        .attr(&quot;stroke-width&quot;, 1.25)
        .attr(&quot;y2&quot;, -125);
    // Operates on both new and old elements
    mult_lines
        .transition()
        .duration(animate * duration)
        .attr(&quot;x1&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })
        .attr(&quot;x2&quot;, function(d, i) {
            return pts_spacing * (i + 0.5) * dilatation;
        })

    // data binding
    const add_lines = root.selectAll(&quot;#addline&quot;).data(data);
    // remove elements no longer in data
    add_lines.exit().transition().duration(animate * duration / 2).attr(&quot;stroke-width&quot;, 0).remove();
    // Create new entry for new elements in data
    const new_add_lines = add_lines
        .enter()
        .append(&quot;path&quot;)
        .attr(&quot;id&quot;, &quot;addline&quot;)
        .attr(&quot;stroke&quot;, add_color)
        .attr(&quot;fill&quot;, &quot;none&quot;);

    // Operates on both new and old elements
    add_lines
        .merge(new_add_lines)
        .transition()
        .duration(animate* duration)
        .attr(&quot;d&quot;, function(d, i) {
            const x_pts = pts_spacing * (i + 0.5) * dilatation;
            const x_middle = pts_spacing * (Math.ceil(data.length / 2) - 0.5) * dilatation;
            const points = [
                [x_pts, Math.max(d.y, -radius / 2) + 10],
                [x_pts, magnitude_max + 10],
                [x_pts, magnitude_max + 20],
                [x_middle, magnitude_max + 20],
                [x_middle, magnitude_max + 25],
                [x_middle, magnitude_max + 150 - magnitude_max],
            ];

            const line = d3
                .line()
                .x(d =&gt; d[0])
                .y(d =&gt; d[1])
                .curve(d3.curveBundle.beta(1));
            return line(points);
        });

    new_add_lines
        .attr(&quot;stroke-width&quot;, 0)
        .transition()
        .duration(animate * duration)
        .attr(&quot;stroke-width&quot;, 1.25);
}


function update() {
    func_padded_fn = padFunc(func_fn, padding);
    // kernel
    updateCenteredLayout(kernel, kernel_fn.length, kernel_line_y, dilatation);
    updateXaxis(kernel, kernel_fn.length, dilatation);
    drawFunction(kernel, kernel_fn, dilatation, kernel_color, true);

    // function
    updatePadLeft();
    updateXaxis(pad_left, padding, 1);
    drawPadding(pad_left, padding);

    updateCenteredLayout(func, func_fn.length, func_line_y, 1);
    updateXaxis(func, func_fn.length, 1);
    drawFunction(func, func_fn, 1, func_color, true);

    updatePadRight();
    updateXaxis(pad_right, padding, 1);
    drawPadding(pad_right, padding);

    // conv-ops
    updateConvLayout();
    // reverse kernel in a non destructive way by making a copy
    const reversed_kernel_fn = [...kernel_fn].reverse();
    updateXaxis(conv, kernel_fn.length, dilatation);
    drawFunction(conv, reversed_kernel_fn, dilatation, kernel_color, true);
    drawConvOps(ops, reversed_kernel_fn, dilatation);

    // result
    out_fn = computeConv(func_padded_fn, reversed_kernel_fn);
    updateOutputLayout();
    updateXaxis(out, out_fn.length, stride);
    drawFunction(out, out_fn, stride, out_color, false);
}
update();
updateEquation();
animate = true;


function getConvRightPosition(step) {
    return step * stride + (kernel_fn.length - 1) * dilatation + 1;
}

//// User input
d3.select(&quot;#radius&quot;).on(&quot;input&quot;, function() {
    radius = Math.max(6, Math.min(this.value, 20));
    this.value = radius;
    update();
});

d3.select(&quot;#dilatation&quot;)
    .on(&quot;input&quot;, function() {
        dilatation = Math.min(Math.max(this.min, this.value), this.max);
        this.value = dilatation;
        while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
            step -= 1;
        }
        update();
        updateEquation();
    })

d3.select(&quot;#stride&quot;)
    .on(&quot;input&quot;, function() {
        stride = Math.min(Math.max(this.min, this.value), this.max);
        this.value = stride;
        while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
            step -= 1;
        }
        update();
        updateEquation();
    });

d3.select(&quot;#padding&quot;)
    .on(&quot;input&quot;, function() {
        padding = Math.min(Math.max(this.min, this.value), this.max);
        this.value = padding;
        while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_fn.length + 2 *padding) {
            step -= 1;
        }
        update();
        updateEquation();
    });

d3.select(&quot;#prevstep&quot;)
    .on(&quot;click&quot;, function() {
        if (step &gt; 0) {
            step -= 1;
            update();
            updateEquation();
        }
    });
d3.select(&quot;#nextstep&quot;)
    .on(&quot;click&quot;, function() {
        if (getConvRightPosition(step) + stride &lt;= func_padded_fn.length) {
            step += 1;
            update();
            updateEquation();
        }
    });

d3.select(&quot;#add-kernel-element&quot;)
    .on(&quot;click&quot;, function() {
        if (kernel_fn.length &lt; kernel_max_support) {
            kernel_fn.push({ y: 0 });
            while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
                step -= 1;
            }
            update();
            updateEquation();
        }
    });
d3.select(&quot;#delete-kernel-element&quot;)
    .on(&quot;click&quot;, function() {
        if (kernel_fn.length &gt; 1) {
            kernel_fn.pop();
            update();
        }
    });

d3.selectAll(&quot;input[name='kernel']&quot;).on(&quot;change&quot;, function(){
    if (this.value == &quot;constant&quot;) {
        kernel_fn = [{y:-magnitude_max}, {y:-magnitude_max}, {y:-magnitude_max}];
    } else if (this.value == &quot;step&quot;) {
        kernel_fn = [{y:0}, {y:0}, {y:-magnitude_max}, {y:-magnitude_max}, {y:-magnitude_max}];
    } else if (this.value == &quot;square&quot;) {
        kernel_fn = [{y:0}, {y:-magnitude_max}, {y:-magnitude_max}, {y:-magnitude_max}, {y:0}];
    } else if (this.value == &quot;triangle&quot;) {
        kernel_fn = [{y:-magnitude_max / 3}, {y:-magnitude_max * 2 / 3}, {y:-magnitude_max}, {y:-magnitude_max * 2 / 3}, {y:-magnitude_max / 3}];
    } else if (this.value == &quot;gaussian&quot;) {
        kernel_fn = [{y:-magnitude_max * 4 / 19}, {y:-magnitude_max * 10 / 18 }, {y:-magnitude_max * 16 / 19}, {y:-magnitude_max}, {y:-magnitude_max * 16 / 19}, {y:-magnitude_max * 10 / 19}, {y:-magnitude_max * 4 / 19}];
    } else if (this.value == &quot;derivative&quot;) {
        kernel_fn = [{y:-magnitude_max}, {y:magnitude_max}];
    }
    while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
        step -= 1;
    }
    update();
    updateEquation();
});

d3.select(&quot;#add-signal-element&quot;)
    .on(&quot;click&quot;, function() {
          func_fn.push({ y: 0 });
          update();
    });
d3.select(&quot;#delete-signal-element&quot;)
    .on(&quot;click&quot;, function() {
          func_fn.pop({ y: 0 });
          func_padded_fn = padFunc(func_fn, padding);
          while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
              step -= 1;
          }
          update();
          updateEquation();
    });
d3.selectAll(&quot;input[name='signal']&quot;).on(&quot;change&quot;, function(){
    if (this.value == &quot;sine&quot;) {
        new_fn = []
        for (let i = 0; i &lt; func_fn.length; i++) {
            new_fn.push({y: Math.cos(i/1.3) * magnitude_max})
        }
        func_fn = new_fn;
    } else if (this.value == &quot;square&quot;) {
        new_fn = []
        for (let i = 0; i &lt; func_fn.length; i++) {
            console.log()
            new_fn.push({y: - (Math.floor(i / 5) + 1)% 2 * magnitude_max})
        }
        func_fn = new_fn;
    } else if (this.value == &quot;ramp&quot;) {
        new_fn = []
        for (let i = 0; i &lt; func_fn.length; i++) {
            new_fn.push({y: - ((i / 5) % 1 * 5/4 - 0.5) * 2 * magnitude_max})
        }
        func_fn = new_fn;
    }
    while (step &gt; 0 &amp;&amp; getConvRightPosition(step) &gt; func_padded_fn.length) {
        step -= 1;
    }
    update();
    updateEquation();
});


d3.select(&quot;#play&quot;)
    .on(&quot;click&quot;, function() {
        d3.selectAll(&quot;*&quot;).interrupt();
        svg.transition().on(&quot;end&quot;, function repeat(d){
            if (getConvRightPosition(step) + stride &lt;= func_padded_fn.length) {
                step += 1;
                update();
                updateEquation();
                d3.active(this).transition().delay(600).on(&quot;start&quot;, repeat);
            }
        })
    });
d3.select(&quot;#reset&quot;)
    .on(&quot;click&quot;, function() {
        d3.selectAll(&quot;*&quot;).interrupt();
        step = 0;
        update();
        updateEquation();
    });
d3.select(&quot;#end&quot;)
    .on(&quot;click&quot;, function() {
        d3.selectAll(&quot;*&quot;).interrupt();
        while (getConvRightPosition(step) + stride &lt;= func_padded_fn.length) {
            step += 1;
        }
        update();
        updateEquation();
    });
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;

</description>
        
        <pubDate>Sun, 17 May 2020 10:25:47 +0000</pubDate>
        <link>https://antoinebrl.github.io//blog/conv1d/</link>
        <guid isPermaLink="true">https://antoinebrl.github.io//blog/conv1d/</guid>
        
        
      </item>
      
    
  </channel>
</rss>
